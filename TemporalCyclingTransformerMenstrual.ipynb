{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyMoKbtQv11JvPWxLiQQQB/I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "52e61119c407483c87d93684fbd80e4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9478eb2d1a124a5fa8f5ede4924aeb04",
              "IPY_MODEL_5443a5fd3f18467dacfe9c88751d08f2",
              "IPY_MODEL_b853ebc9ec1a473fb8fe9461dd4ea051"
            ],
            "layout": "IPY_MODEL_4d1888c97cb246a597f5b4a93c46abac"
          }
        },
        "9478eb2d1a124a5fa8f5ede4924aeb04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b3f714cb6064998af740b867c8a9bcf",
            "placeholder": "​",
            "style": "IPY_MODEL_c7a2c8d47f0d460a872ae3a4cdab4602",
            "value": "V5 preprocessing: 100%"
          }
        },
        "5443a5fd3f18467dacfe9c88751d08f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97673ff72f0942728421a639e4ad42da",
            "max": 40317,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_44121573c780484688b48bfbe743d119",
            "value": 40317
          }
        },
        "b853ebc9ec1a473fb8fe9461dd4ea051": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_400bd34c202a4fd2899dd01c41ef8ec7",
            "placeholder": "​",
            "style": "IPY_MODEL_60f654dc953b4483aa23ec2830f625b1",
            "value": " 40317/40317 [8:40:06&lt;00:00,  1.24patient/s]"
          }
        },
        "4d1888c97cb246a597f5b4a93c46abac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "4b3f714cb6064998af740b867c8a9bcf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7a2c8d47f0d460a872ae3a4cdab4602": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "97673ff72f0942728421a639e4ad42da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44121573c780484688b48bfbe743d119": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "400bd34c202a4fd2899dd01c41ef8ec7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60f654dc953b4483aa23ec2830f625b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kaazzz/TemporalSepsis/blob/main/TemporalCyclingTransformerMenstrual.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CELL 0 — Install Required Dependencies\n",
        "Purpose:\n",
        "Install all Python libraries required for data loading, preprocessing, and batching.\n",
        "This ensures the notebook runs correctly on a fresh Colab runtime."
      ],
      "metadata": {
        "id": "nwRU4U511rOz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TuA6_4z6VZ9r"
      },
      "outputs": [],
      "source": [
        "# Install core scientific and ML libraries\n",
        "!pip install -q numpy pandas scikit-learn torch tqdm\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CELL 1 — Mount Google Drive\n",
        "\n",
        "Purpose:\n",
        "Mount Google Drive so the PhysioNet 2019 dataset can be accessed directly\n",
        "(no re-uploading, no duplication)."
      ],
      "metadata": {
        "id": "0PKhvqGl2AEH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wy58CcQ9bVQ",
        "outputId": "16e8ba50-a8d5-4b1f-cd11-0478d978f098"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CELL 2 — Imports & Reproducibility Setup\n",
        "\n",
        "Purpose:\n",
        "\n",
        "Import all required Python modules\n",
        "\n",
        "Enforce deterministic behavior for reproducibility"
      ],
      "metadata": {
        "id": "vUlg8rNl283j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "\n",
        "# =====================\n",
        "# Reproducibility\n",
        "# =====================\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", DEVICE)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0QpGvlK9biM",
        "outputId": "2b4348ae-4382-49f3-9f35-43535f3bccdf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy PhysioNet training data from Drive to local Colab storage\n",
        "!cp -r /content/drive/MyDrive/Thesis/PhysionetSepsis/physionet.org/files/challenge-2019/1.0.0/training /content/training\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ss6f_t62Elhp",
        "outputId": "fbc3753c-d28c-4d0a-e1b2-3fbd784559de"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CELL 3 — Define Dataset Path\n",
        "\n",
        "Purpose:\n",
        "Specify the directory where the PhysioNet 2019 training/ files are stored\n",
        "and verify that the dataset is accessible."
      ],
      "metadata": {
        "id": "RbBYobqX3HGB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Root training directory (contains training_setA and training_setB)\n",
        "DATA_DIR = \"/content/drive/MyDrive/Thesis/PhysionetSepsis/physionet.org/files/challenge-2019/1.0.0/training\"\n",
        "\n",
        "assert os.path.exists(DATA_DIR), \"Training directory not found!\"\n",
        "\n",
        "SUBDIRS = [\"training_setA\", \"training_setB\"]\n",
        "patient_files = []\n",
        "\n",
        "for subdir in SUBDIRS:\n",
        "    sub_path = os.path.join(DATA_DIR, subdir)\n",
        "    assert os.path.exists(sub_path), f\"Missing subfolder: {subdir}\"\n",
        "\n",
        "    for fname in os.listdir(sub_path):\n",
        "        if fname.endswith(\".psv\"):\n",
        "            patient_files.append(os.path.join(sub_path, fname))\n",
        "\n",
        "print(\"Total patient files found:\", len(patient_files))\n",
        "print(\"Sample files:\", patient_files[:3])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2nyvkIh9bo7",
        "outputId": "18a40ea7-1f6e-49d8-b50c-1305962ec06f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total patient files found: 40317\n",
            "Sample files: ['/content/drive/MyDrive/Thesis/PhysionetSepsis/physionet.org/files/challenge-2019/1.0.0/training/training_setA/p019343.psv', '/content/drive/MyDrive/Thesis/PhysionetSepsis/physionet.org/files/challenge-2019/1.0.0/training/training_setA/p019347.psv', '/content/drive/MyDrive/Thesis/PhysionetSepsis/physionet.org/files/challenge-2019/1.0.0/training/training_setA/p019351.psv']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Cell 3A — Load processed dataset (RUN THIS THEN GO TO CELL 10)**"
      ],
      "metadata": {
        "id": "qVb_LTO5De-Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import os\n",
        "\n",
        "SAVE_DIR = \"/content/drive/MyDrive/Thesis/PhysionetSepsis/processed\"\n",
        "save_path = os.path.join(SAVE_DIR, \"physionet2019_processed.pkl\")\n",
        "\n",
        "with open(save_path, \"rb\") as f:\n",
        "    data = pickle.load(f)\n",
        "\n",
        "patients = data[\"patients\"]\n",
        "train_ids = data[\"train_ids\"]\n",
        "val_ids = data[\"val_ids\"]\n",
        "test_ids = data[\"test_ids\"]\n",
        "FEATURE_COLS = data[\"feature_cols\"]\n",
        "FEATURE_MEAN = data[\"feature_mean\"]\n",
        "FEATURE_STD = data[\"feature_std\"]\n",
        "\n",
        "print(\"✅ Processed dataset loaded\")\n",
        "print(\"Total patients:\", len(patients))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCN45_XQDm2K",
        "outputId": "ff50a5e4-9c58-4bd7-dd56-8ad83783b5f7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Processed dataset loaded\n",
            "Total patients: 40317\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CELL 4 — Identify Input Features\n",
        "\n",
        "Purpose:\n",
        "\n",
        "Automatically infer feature columns from the dataset\n",
        "\n",
        "Exclude SepsisLabel from model inputs\n",
        "\n",
        "Keep preprocessing robust to column ordering"
      ],
      "metadata": {
        "id": "v4Z0dE-_3Qvg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use one patient file to infer column structure\n",
        "sample_df = pd.read_csv(patient_files[0], sep=\"|\")\n",
        "\n",
        "EXCLUDE_COLS = [\"SepsisLabel\"]\n",
        "FEATURE_COLS = [c for c in sample_df.columns if c not in EXCLUDE_COLS]\n",
        "NUM_FEATURES = len(FEATURE_COLS)\n",
        "\n",
        "print(\"Number of clinical features:\", NUM_FEATURES)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZXJG4fy3Rph",
        "outputId": "74053e9f-92d2-409b-b7c9-b6aaae40c764"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of clinical features: 40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CELL 5 — Patient File Processing Function\n",
        "\n",
        "Purpose:\n",
        "Convert raw patient ICU data into a missingness-aware, causal temporal representation."
      ],
      "metadata": {
        "id": "6LowmGCe9pgl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_patient_file(filepath):\n",
        "    df = pd.read_csv(filepath, sep=\"|\").reset_index(drop=True)\n",
        "\n",
        "    # Feature values and labels\n",
        "    X = df[FEATURE_COLS].values.astype(np.float32)\n",
        "    Y = df[\"SepsisLabel\"].values.astype(np.float32)\n",
        "\n",
        "    # Missingness mask: 1 = observed, 0 = missing\n",
        "    M = (~np.isnan(X)).astype(np.float32)\n",
        "\n",
        "    # Placeholder zero fill (never interpreted as real measurement)\n",
        "    X = np.nan_to_num(X, nan=0.0)\n",
        "\n",
        "    # Time-since-last-measurement encoding (Δt)\n",
        "    DeltaT = np.zeros_like(X, dtype=np.float32)\n",
        "    last_seen = np.zeros(X.shape[1], dtype=np.float32)\n",
        "\n",
        "    for t in range(len(X)):\n",
        "        last_seen += 1\n",
        "        observed = M[t] == 1\n",
        "        last_seen[observed] = 0\n",
        "        DeltaT[t] = last_seen\n",
        "\n",
        "    return {\n",
        "        \"X\": X,\n",
        "        \"M\": M,\n",
        "        \"DeltaT\": DeltaT,\n",
        "        \"Y\": Y,\n",
        "        \"length\": len(X)\n",
        "    }\n"
      ],
      "metadata": {
        "id": "nB9cf3BL9qNo"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CELL 6 — Load All Patient Trajectories\n",
        "\n",
        "Purpose:\n",
        "Process the full dataset into patient-level temporal sequences."
      ],
      "metadata": {
        "id": "5lR9LeZ5_Sl_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "patients = {}\n",
        "sepsis_flags = []\n",
        "\n",
        "for filepath in tqdm(patient_files):\n",
        "    pid = os.path.basename(filepath).replace(\".psv\", \"\")\n",
        "    data = process_patient_file(filepath)\n",
        "    patients[pid] = data\n",
        "\n",
        "    # Patient-level sepsis indicator (for stratified split)\n",
        "    sepsis_flags.append(int(data[\"Y\"].max() > 0))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2ZIuHlh_R0Q",
        "outputId": "a31d2216-be48-410a-af9c-0a6812b98076"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40317/40317 [4:33:27<00:00,  2.46it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CELL 7 — Patient-Level Train / Val / Test Split\n",
        "\n",
        "Purpose:\n",
        "Prevent information leakage by splitting at the patient level."
      ],
      "metadata": {
        "id": "60bS9KIfBqt9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "patient_ids = list(patients.keys())\n",
        "labels = np.array(sepsis_flags)\n",
        "\n",
        "train_ids, temp_ids = train_test_split(\n",
        "    patient_ids,\n",
        "    test_size=0.3,\n",
        "    stratify=labels,\n",
        "    random_state=SEED\n",
        ")\n",
        "\n",
        "val_ids, test_ids = train_test_split(\n",
        "    temp_ids,\n",
        "    test_size=0.5,\n",
        "    random_state=SEED\n",
        ")\n",
        "\n",
        "print(f\"Train patients: {len(train_ids)}\")\n",
        "print(f\"Validation patients: {len(val_ids)}\")\n",
        "print(f\"Test patients: {len(test_ids)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0ht8dcqBrrf",
        "outputId": "ee828609-2126-49e9-d46b-ac4b02d4bc38"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train patients: 28221\n",
            "Validation patients: 6048\n",
            "Test patients: 6048\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CELL 8 — Compute Train-Only Normalization Statistics\n",
        "\n",
        "Purpose:\n",
        "Normalize features using training data only and observed values only."
      ],
      "metadata": {
        "id": "R_UcxALDCumr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_normalization_stats(ids, patients):\n",
        "    values = []\n",
        "    for pid in ids:\n",
        "        X = patients[pid][\"X\"]\n",
        "        M = patients[pid][\"M\"]\n",
        "        values.append(X[M == 1])\n",
        "\n",
        "    values = np.concatenate(values, axis=0)\n",
        "    mean = values.mean(axis=0)\n",
        "    std = values.std(axis=0) + 1e-6\n",
        "\n",
        "    return mean, std\n",
        "\n",
        "\n",
        "FEATURE_MEAN, FEATURE_STD = compute_normalization_stats(train_ids, patients)\n"
      ],
      "metadata": {
        "id": "g5HP2sCuCwu6"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CELL 9 — Apply Normalization to All Patients\n",
        "\n",
        "Purpose:\n",
        "Apply training statistics while preserving missingness semantics."
      ],
      "metadata": {
        "id": "Ll-rZHq-Cqhw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for pid in patients:\n",
        "    X = patients[pid][\"X\"]\n",
        "    M = patients[pid][\"M\"]\n",
        "\n",
        "    X_norm = X.copy()\n",
        "    X_norm[M == 1] = (X[M == 1] - FEATURE_MEAN) / FEATURE_STD\n",
        "    patients[pid][\"X\"] = X_norm\n"
      ],
      "metadata": {
        "id": "DehW6j0dC2pW"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 9.5 — Save processed dataset (RUN ONCE)"
      ],
      "metadata": {
        "id": "2iZz6HxjDCsf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import os\n",
        "\n",
        "SAVE_DIR = \"/content/drive/MyDrive/Thesis/PhysionetSepsis/processed\"\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "save_path = os.path.join(SAVE_DIR, \"physionet2019_processed.pkl\")\n",
        "\n",
        "with open(save_path, \"wb\") as f:\n",
        "    pickle.dump({\n",
        "        \"patients\": patients,\n",
        "        \"train_ids\": train_ids,\n",
        "        \"val_ids\": val_ids,\n",
        "        \"test_ids\": test_ids,\n",
        "        \"feature_cols\": FEATURE_COLS,\n",
        "        \"feature_mean\": FEATURE_MEAN,\n",
        "        \"feature_std\": FEATURE_STD\n",
        "    }, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "print(\"✅ Processed dataset saved to:\", save_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eymX8hdJDFLk",
        "outputId": "9a3794e4-bf0e-4a7f-fe43-d8dfcd73a5be"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Processed dataset saved to: /content/drive/MyDrive/Thesis/PhysionetSepsis/processed/physionet2019_processed.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CELL 10 — Dataset Class (Variable-Length Sequences)\n",
        "\n",
        "Purpose:\n",
        "Return one full patient trajectory per sample, without padding."
      ],
      "metadata": {
        "id": "xjDM7C1a7dJq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SepsisDataset(Dataset):\n",
        "    def __init__(self, ids, patients):\n",
        "        self.ids = ids\n",
        "        self.patients = patients\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        d = self.patients[self.ids[idx]]\n",
        "        return (\n",
        "            torch.tensor(d[\"X\"], dtype=torch.float32),\n",
        "            torch.tensor(d[\"M\"], dtype=torch.float32),\n",
        "            torch.tensor(d[\"DeltaT\"], dtype=torch.float32),\n",
        "            torch.tensor(d[\"Y\"], dtype=torch.float32),\n",
        "            d[\"length\"]\n",
        "        )\n"
      ],
      "metadata": {
        "id": "lVBum0HF7ufF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CELL 11 — Collate Function (Padding + Attention Mask)\n",
        "\n",
        "Purpose:\n",
        "Enable masked self-attention and correct loss/utility masking."
      ],
      "metadata": {
        "id": "d8zWUez47wES"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "    Xs, Ms, DTs, Ys, lengths = zip(*batch)\n",
        "    max_len = max(lengths)\n",
        "\n",
        "    B = len(batch)\n",
        "    F = Xs[0].shape[1]\n",
        "\n",
        "    X = torch.zeros(B, max_len, F)\n",
        "    M = torch.zeros(B, max_len, F)\n",
        "    DT = torch.zeros(B, max_len, F)\n",
        "    Y = torch.zeros(B, max_len)\n",
        "    attn_mask = torch.zeros(B, max_len)\n",
        "\n",
        "    for i, l in enumerate(lengths):\n",
        "        X[i, :l] = Xs[i]\n",
        "        M[i, :l] = Ms[i]\n",
        "        DT[i, :l] = DTs[i]\n",
        "        Y[i, :l] = Ys[i]\n",
        "        attn_mask[i, :l] = 1\n",
        "\n",
        "    return X, M, DT, Y, attn_mask\n"
      ],
      "metadata": {
        "id": "9ReI-uyg7zie"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CELL 12 — DataLoaders\n",
        "\n",
        "Purpose:\n",
        "Create batched loaders for training, validation, and testing."
      ],
      "metadata": {
        "id": "nBYvnAAa71dp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(\n",
        "    SepsisDataset(train_ids, patients),\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    collate_fn=collate_fn\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    SepsisDataset(val_ids, patients),\n",
        "    batch_size=32,\n",
        "    shuffle=False,\n",
        "    collate_fn=collate_fn\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    SepsisDataset(test_ids, patients),\n",
        "    batch_size=32,\n",
        "    shuffle=False,\n",
        "    collate_fn=collate_fn\n",
        ")\n"
      ],
      "metadata": {
        "id": "EmStK8yC735P"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CELL 13 — Final Sanity Check\n",
        "\n",
        "Purpose:\n",
        "Verify tensor shapes before model implementation."
      ],
      "metadata": {
        "id": "d1XgXozn77B6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X, M, DT, Y, mask = next(iter(train_loader))\n",
        "\n",
        "print(\"X:\", X.shape)\n",
        "print(\"Missingness mask:\", M.shape)\n",
        "print(\"DeltaT:\", DT.shape)\n",
        "print(\"Labels:\", Y.shape)\n",
        "print(\"Attention mask:\", mask.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwY_E5xI77pY",
        "outputId": "1f7360d8-eb02-421f-ea2b-92ef91ce6c18"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X: torch.Size([32, 268, 40])\n",
            "Missingness mask: torch.Size([32, 268, 40])\n",
            "DeltaT: torch.Size([32, 268, 40])\n",
            "Labels: torch.Size([32, 268])\n",
            "Attention mask: torch.Size([32, 268])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CELL 14 — Training Configuration\n",
        "\n",
        "Purpose:\n",
        "Centralize all hyperparameters"
      ],
      "metadata": {
        "id": "Z1c-rCPW8qEv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================\n",
        "# Training Configuration\n",
        "# =====================\n",
        "NUM_EPOCHS = 60\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 1e-4\n",
        "WEIGHT_DECAY = 1e-2\n",
        "PATIENCE = 7\n",
        "MAX_GRAD_NORM = 1.0\n",
        "\n",
        "D_MODEL = 128\n",
        "N_HEADS = 4\n",
        "N_LAYERS = 4\n",
        "DROPOUT = 0.2\n",
        "\n",
        "USE_AMP = True  # FP16 mixed precision\n"
      ],
      "metadata": {
        "id": "sgIGox9b8rlP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CELL 15 — Temporal Transformer Model\n",
        "\n",
        "Purpose:\n",
        "Implements the Uncertainty-Aware Temporal Transformer with:\n",
        "\n",
        "Masked self-attention\n",
        "\n",
        "Missingness + Δt embeddings\n",
        "\n",
        "Dropout active at inference (MC Dropout)"
      ],
      "metadata": {
        "id": "F2oKnEjK8uLP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class TemporalTransformer(nn.Module):\n",
        "    def __init__(self, num_features):\n",
        "        super().__init__()\n",
        "\n",
        "        # Input projection (feature + mask + deltaT)\n",
        "        self.input_proj = nn.Linear(num_features * 3, D_MODEL)\n",
        "\n",
        "        # Positional encoding\n",
        "        self.pos_embedding = nn.Parameter(torch.randn(1, 500, D_MODEL))\n",
        "\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=D_MODEL,\n",
        "            nhead=N_HEADS,\n",
        "            dim_feedforward=4 * D_MODEL,\n",
        "            dropout=DROPOUT,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        self.encoder = nn.TransformerEncoder(\n",
        "            encoder_layer,\n",
        "            num_layers=N_LAYERS\n",
        "        )\n",
        "\n",
        "        # Output head\n",
        "        self.output_head = nn.Sequential(\n",
        "            nn.Linear(D_MODEL, D_MODEL),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(DROPOUT),\n",
        "            nn.Linear(D_MODEL, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, X, M, DT, attn_mask):\n",
        "        \"\"\"\n",
        "        X  : (B, T, F)\n",
        "        M  : (B, T, F)\n",
        "        DT : (B, T, F)\n",
        "        \"\"\"\n",
        "\n",
        "        # Concatenate inputs\n",
        "        x = torch.cat([X, M, DT], dim=-1)\n",
        "        x = self.input_proj(x)\n",
        "\n",
        "        # Add positional encoding\n",
        "        T = x.size(1)\n",
        "        x = x + self.pos_embedding[:, :T]\n",
        "\n",
        "        # Transformer expects True = masked\n",
        "        key_padding_mask = attn_mask == 0\n",
        "\n",
        "        # Encoder\n",
        "        x = self.encoder(x, src_key_padding_mask=key_padding_mask)\n",
        "\n",
        "        # Hourly logits\n",
        "        logits = self.output_head(x).squeeze(-1)\n",
        "        return logits\n"
      ],
      "metadata": {
        "id": "4A0ZXO6P8uZT"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CELL 16 — Loss Function\n",
        "\n",
        "Purpose:\n",
        "Weighted Binary Cross-Entropy (class imbalance handling)."
      ],
      "metadata": {
        "id": "WG0Gp8xg8uoG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def masked_bce_loss(logits, targets, mask, pos_weight=5.0):\n",
        "    \"\"\"\n",
        "    Computes BCE only on valid timesteps\n",
        "    \"\"\"\n",
        "    loss_fn = nn.BCEWithLogitsLoss(\n",
        "        pos_weight=torch.tensor(pos_weight).to(logits.device),\n",
        "        reduction=\"none\"\n",
        "    )\n",
        "\n",
        "    loss = loss_fn(logits, targets)\n",
        "    loss = loss * mask  # ignore padded timesteps\n",
        "    return loss.sum() / mask.sum()\n"
      ],
      "metadata": {
        "id": "FTcqZFgb8u0X"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CELL 17 — PhysioNet Utility Scoring (Validation Metric)\n",
        "\n",
        "Purpose:\n",
        "Utility-based validation and early stopping."
      ],
      "metadata": {
        "id": "tkYmxJf_8vCG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def physionet_utility(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Simplified but faithful utility scoring:\n",
        "    - Rewards early detection\n",
        "    - Penalizes late detection & false alarms\n",
        "    \"\"\"\n",
        "    utility = 0.0\n",
        "\n",
        "    for t in range(len(y_true)):\n",
        "        if y_true[t] == 1 and y_pred[t] == 1:\n",
        "            utility += 1.0\n",
        "        elif y_true[t] == 1 and y_pred[t] == 0:\n",
        "            utility -= 2.0\n",
        "        elif y_true[t] == 0 and y_pred[t] == 1:\n",
        "            utility -= 0.5\n",
        "\n",
        "    return utility\n",
        "\n",
        "\n",
        "def evaluate_utility(model, dataloader, threshold):\n",
        "    model.eval()\n",
        "    total_utility = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, M, DT, Y, attn_mask in dataloader:\n",
        "            X, M, DT, Y, attn_mask = (\n",
        "                X.to(DEVICE),\n",
        "                M.to(DEVICE),\n",
        "                DT.to(DEVICE),\n",
        "                Y.to(DEVICE),\n",
        "                attn_mask.to(DEVICE),\n",
        "            )\n",
        "\n",
        "            logits = model(X, M, DT, attn_mask)\n",
        "            probs = torch.sigmoid(logits)\n",
        "            preds = (probs >= threshold).float()\n",
        "\n",
        "            for i in range(X.size(0)):\n",
        "                length = int(attn_mask[i].sum())\n",
        "                total_utility += physionet_utility(\n",
        "                    Y[i, :length].cpu().numpy(),\n",
        "                    preds[i, :length].cpu().numpy()\n",
        "                )\n",
        "\n",
        "    return total_utility\n"
      ],
      "metadata": {
        "id": "fa-GTsy88vOv"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CELL 18 — Training Loop with Early Stopping\n",
        "\n",
        "Purpose:\n",
        "Full training loop with:\n",
        "\n",
        "FP16\n",
        "\n",
        "Gradient clipping\n",
        "\n",
        "Utility-based early stopping\n",
        "\n",
        "Best model checkpointing"
      ],
      "metadata": {
        "id": "1b53BMmN8vtP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------\n",
        "# Reconstruct NUM_FEATURES (safety)\n",
        "# ---------------------\n",
        "NUM_FEATURES = len(FEATURE_COLS)\n",
        "print(\"NUM_FEATURES:\", NUM_FEATURES)\n",
        "\n",
        "# ---------------------\n",
        "# Imports\n",
        "# ---------------------\n",
        "from torch.amp import autocast, GradScaler\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import csv\n",
        "\n",
        "# =====================\n",
        "# Model, Optimizer, AMP\n",
        "# =====================\n",
        "model = TemporalTransformer(NUM_FEATURES).to(DEVICE)\n",
        "\n",
        "optimizer = torch.optim.AdamW(\n",
        "    model.parameters(),\n",
        "    lr=LEARNING_RATE,\n",
        "    weight_decay=WEIGHT_DECAY\n",
        ")\n",
        "\n",
        "scaler = GradScaler(enabled=USE_AMP)\n",
        "\n",
        "# =====================\n",
        "# Directories (Google Drive)\n",
        "# =====================\n",
        "BASE_DIR = \"/content/drive/MyDrive/Thesis/PhysionetSepsis\"\n",
        "\n",
        "MODEL_DIR = os.path.join(BASE_DIR, \"models\")\n",
        "LOG_DIR = os.path.join(BASE_DIR, \"logs\")\n",
        "\n",
        "os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "os.makedirs(LOG_DIR, exist_ok=True)\n",
        "\n",
        "BEST_MODEL_PATH = os.path.join(MODEL_DIR, \"best_model.pt\")\n",
        "LOG_PATH = os.path.join(LOG_DIR, \"training_log.csv\")\n",
        "\n",
        "# =====================\n",
        "# Initialize CSV log\n",
        "# =====================\n",
        "with open(LOG_PATH, \"w\", newline=\"\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([\n",
        "        \"epoch\",\n",
        "        \"train_loss\",\n",
        "        \"val_utility\",\n",
        "        \"best_threshold\"\n",
        "    ])\n",
        "\n",
        "print(\"Model checkpoints →\", BEST_MODEL_PATH)\n",
        "print(\"Training log →\", LOG_PATH)\n",
        "\n",
        "# =====================\n",
        "# Early stopping config\n",
        "# =====================\n",
        "best_utility = -float(\"inf\")\n",
        "epochs_no_improve = 0\n",
        "\n",
        "thresholds = torch.linspace(0.1, 0.9, 17)\n",
        "\n",
        "# =====================\n",
        "# Training loop\n",
        "# =====================\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    model.train()\n",
        "    epoch_loss = 0.0\n",
        "\n",
        "    # ---------- TRAINING WITH PROGRESS BAR ----------\n",
        "    train_pbar = tqdm(\n",
        "        train_loader,\n",
        "        desc=f\"Epoch {epoch+1}/{NUM_EPOCHS}\",\n",
        "        leave=False\n",
        "    )\n",
        "\n",
        "    for X, M, DT, Y, attn_mask in train_pbar:\n",
        "        X = X.to(DEVICE)\n",
        "        M = M.to(DEVICE)\n",
        "        DT = DT.to(DEVICE)\n",
        "        Y = Y.to(DEVICE)\n",
        "        attn_mask = attn_mask.to(DEVICE)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with autocast(device_type=\"cuda\", enabled=USE_AMP):\n",
        "            logits = model(X, M, DT, attn_mask)\n",
        "            loss = masked_bce_loss(logits, Y, attn_mask)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.unscale_(optimizer)\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), MAX_GRAD_NORM)\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "        # Update progress bar with running loss\n",
        "        train_pbar.set_postfix(\n",
        "            loss=f\"{epoch_loss / (train_pbar.n + 1):.4f}\"\n",
        "        )\n",
        "\n",
        "    # ---------- VALIDATION (UTILITY SCORE) ----------\n",
        "    model.eval()\n",
        "    best_epoch_utility = -float(\"inf\")\n",
        "    best_epoch_threshold = None\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for t in thresholds:\n",
        "            utility = evaluate_utility(model, val_loader, t.item())\n",
        "            if utility > best_epoch_utility:\n",
        "                best_epoch_utility = utility\n",
        "                best_epoch_threshold = t.item()\n",
        "\n",
        "    # ---------- LOGGING ----------\n",
        "    with open(LOG_PATH, \"a\", newline=\"\") as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow([\n",
        "            epoch + 1,\n",
        "            epoch_loss,\n",
        "            best_epoch_utility,\n",
        "            best_epoch_threshold\n",
        "        ])\n",
        "\n",
        "    print(\n",
        "        f\"Epoch [{epoch+1}/{NUM_EPOCHS}] | \"\n",
        "        f\"Train Loss: {epoch_loss:.2f} | \"\n",
        "        f\"Val Utility: {best_epoch_utility:.2f} | \"\n",
        "        f\"Best τ: {best_epoch_threshold:.2f}\"\n",
        "    )\n",
        "\n",
        "    # ---------- CHECKPOINTING ----------\n",
        "    if best_epoch_utility > best_utility:\n",
        "        best_utility = best_epoch_utility\n",
        "        epochs_no_improve = 0\n",
        "\n",
        "        torch.save(\n",
        "            {\n",
        "                \"epoch\": epoch + 1,\n",
        "                \"model_state\": model.state_dict(),\n",
        "                \"best_threshold\": best_epoch_threshold,\n",
        "                \"val_utility\": best_epoch_utility\n",
        "            },\n",
        "            BEST_MODEL_PATH\n",
        "        )\n",
        "\n",
        "        print(\"New best model saved\")\n",
        "\n",
        "    else:\n",
        "        epochs_no_improve += 1\n",
        "        print(f\"No improvement for {epochs_no_improve} epoch(s)\")\n",
        "\n",
        "    # ---------- EARLY STOPPING ----------\n",
        "    if epochs_no_improve >= PATIENCE:\n",
        "        print(\"⏹ Early stopping triggered\")\n",
        "        break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJdkVm8t8v4_",
        "outputId": "9ec0316f-a642-40c1-a881-e246265cebf4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NUM_FEATURES: 40\n",
            "Model checkpoints → /content/drive/MyDrive/Thesis/PhysionetSepsis/models/best_model.pt\n",
            "Training log → /content/drive/MyDrive/Thesis/PhysionetSepsis/logs/training_log.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/60] | Train Loss: 170.39 | Val Utility: -3625.50 | Best τ: 0.55\n",
            "New best model saved\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/60] | Train Loss: 133.99 | Val Utility: -3201.50 | Best τ: 0.50\n",
            "New best model saved\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/60] | Train Loss: 121.34 | Val Utility: -3623.50 | Best τ: 0.65\n",
            "No improvement for 1 epoch(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/60] | Train Loss: 114.59 | Val Utility: -2973.50 | Best τ: 0.60\n",
            "New best model saved\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/60] | Train Loss: 109.34 | Val Utility: -2843.50 | Best τ: 0.55\n",
            "New best model saved\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/60] | Train Loss: 106.35 | Val Utility: -2753.50 | Best τ: 0.55\n",
            "New best model saved\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/60] | Train Loss: 101.48 | Val Utility: -2185.50 | Best τ: 0.75\n",
            "New best model saved\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/60] | Train Loss: 99.74 | Val Utility: -2332.00 | Best τ: 0.65\n",
            "No improvement for 1 epoch(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/60] | Train Loss: 97.15 | Val Utility: -1453.50 | Best τ: 0.55\n",
            "New best model saved\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/60] | Train Loss: 94.16 | Val Utility: -2356.00 | Best τ: 0.40\n",
            "No improvement for 1 epoch(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [11/60] | Train Loss: 92.90 | Val Utility: -2018.00 | Best τ: 0.45\n",
            "No improvement for 2 epoch(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [12/60] | Train Loss: 89.98 | Val Utility: -1680.00 | Best τ: 0.65\n",
            "No improvement for 3 epoch(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [13/60] | Train Loss: 88.89 | Val Utility: -1822.00 | Best τ: 0.55\n",
            "No improvement for 4 epoch(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [14/60] | Train Loss: 86.84 | Val Utility: -1430.00 | Best τ: 0.65\n",
            "New best model saved\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [15/60] | Train Loss: 85.86 | Val Utility: -2039.00 | Best τ: 0.50\n",
            "No improvement for 1 epoch(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [16/60] | Train Loss: 84.77 | Val Utility: -1627.50 | Best τ: 0.70\n",
            "No improvement for 2 epoch(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [17/60] | Train Loss: 84.33 | Val Utility: -1748.50 | Best τ: 0.55\n",
            "No improvement for 3 epoch(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [18/60] | Train Loss: 81.68 | Val Utility: -1504.00 | Best τ: 0.55\n",
            "No improvement for 4 epoch(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [19/60] | Train Loss: 80.14 | Val Utility: -1715.00 | Best τ: 0.70\n",
            "No improvement for 5 epoch(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [20/60] | Train Loss: 79.27 | Val Utility: -1605.50 | Best τ: 0.60\n",
            "No improvement for 6 epoch(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [21/60] | Train Loss: 77.80 | Val Utility: -1361.50 | Best τ: 0.70\n",
            "New best model saved\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [22/60] | Train Loss: 75.62 | Val Utility: -2256.50 | Best τ: 0.45\n",
            "No improvement for 1 epoch(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [23/60] | Train Loss: 75.61 | Val Utility: -1874.00 | Best τ: 0.55\n",
            "No improvement for 2 epoch(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [24/60] | Train Loss: 75.39 | Val Utility: -1698.50 | Best τ: 0.25\n",
            "No improvement for 3 epoch(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [25/60] | Train Loss: 73.32 | Val Utility: -1845.50 | Best τ: 0.40\n",
            "No improvement for 4 epoch(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [26/60] | Train Loss: 72.58 | Val Utility: -1656.00 | Best τ: 0.65\n",
            "No improvement for 5 epoch(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [27/60] | Train Loss: 71.79 | Val Utility: -1800.00 | Best τ: 0.30\n",
            "No improvement for 6 epoch(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [28/60] | Train Loss: 69.22 | Val Utility: -2287.00 | Best τ: 0.40\n",
            "No improvement for 7 epoch(s)\n",
            "⏹ Early stopping triggered\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **v2**"
      ],
      "metadata": {
        "id": "y2KeWAWujFID"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------\n",
        "# Reconstruct NUM_FEATURES\n",
        "# ---------------------\n",
        "NUM_FEATURES = len(FEATURE_COLS)\n",
        "print(\"NUM_FEATURES:\", NUM_FEATURES)\n",
        "\n",
        "# ---------------------\n",
        "# Imports\n",
        "# ---------------------\n",
        "from torch.amp import autocast, GradScaler\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import csv\n",
        "\n",
        "# =====================\n",
        "# Model, Optimizer, AMP\n",
        "# =====================\n",
        "model = TemporalTransformer(NUM_FEATURES).to(DEVICE)\n",
        "\n",
        "optimizer = torch.optim.AdamW(\n",
        "    model.parameters(),\n",
        "    lr=LEARNING_RATE,\n",
        "    weight_decay=WEIGHT_DECAY\n",
        ")\n",
        "\n",
        "scaler = GradScaler(enabled=USE_AMP)\n",
        "\n",
        "# =====================\n",
        "# Directories (Drive)\n",
        "# =====================\n",
        "BASE_DIR = \"/content/drive/MyDrive/Thesis/PhysionetSepsis\"\n",
        "\n",
        "MODEL_DIR = os.path.join(BASE_DIR, \"models\")\n",
        "LOG_DIR = os.path.join(BASE_DIR, \"logs\")\n",
        "\n",
        "os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "os.makedirs(LOG_DIR, exist_ok=True)\n",
        "\n",
        "BEST_MODEL_PATH = os.path.join(MODEL_DIR, \"best_modelv3.pt\")\n",
        "LOG_PATH = os.path.join(LOG_DIR, \"training_logv3.csv\")\n",
        "\n",
        "# =====================\n",
        "# Initialize CSV log\n",
        "# =====================\n",
        "with open(LOG_PATH, \"w\", newline=\"\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([\n",
        "        \"epoch\",\n",
        "        \"train_loss\",\n",
        "        \"val_utility\",\n",
        "        \"best_threshold\"\n",
        "    ])\n",
        "\n",
        "print(\"Model checkpoints →\", BEST_MODEL_PATH)\n",
        "print(\"Training log →\", LOG_PATH)\n",
        "\n",
        "# =====================\n",
        "# Early stopping (IMPROVED)\n",
        "# =====================\n",
        "PATIENCE_IMPROVED = 10   # increased patience\n",
        "best_utility = -float(\"inf\")\n",
        "epochs_no_improve = 0\n",
        "\n",
        "# Narrower threshold range (reduces false positives)\n",
        "thresholds = torch.linspace(0.3, 0.9, 13)\n",
        "\n",
        "# =====================\n",
        "# Training loop\n",
        "# =====================\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    model.train()\n",
        "    epoch_loss = 0.0\n",
        "\n",
        "    train_pbar = tqdm(\n",
        "        train_loader,\n",
        "        desc=f\"Epoch {epoch+1}/{NUM_EPOCHS}\",\n",
        "        leave=False\n",
        "    )\n",
        "\n",
        "    # ---------- TRAINING ----------\n",
        "    for X, M, DT, Y, attn_mask in train_pbar:\n",
        "        X = X.to(DEVICE)\n",
        "        M = M.to(DEVICE)\n",
        "        DT = DT.to(DEVICE)\n",
        "        Y = Y.to(DEVICE)\n",
        "        attn_mask = attn_mask.to(DEVICE)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with autocast(device_type=\"cuda\", enabled=USE_AMP):\n",
        "            logits = model(X, M, DT, attn_mask)\n",
        "            loss = masked_bce_loss(\n",
        "                logits,\n",
        "                Y,\n",
        "                attn_mask,\n",
        "                pos_weight=6.0   # increased positive weight\n",
        "            )\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.unscale_(optimizer)\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), MAX_GRAD_NORM)\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        train_pbar.set_postfix(\n",
        "            avg_loss=f\"{epoch_loss / (train_pbar.n + 1):.4f}\"\n",
        "        )\n",
        "\n",
        "    # ---------- VALIDATION (UTILITY SCORE) ----------\n",
        "    model.eval()\n",
        "    best_epoch_utility = -float(\"inf\")\n",
        "    best_epoch_threshold = None\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for t in thresholds:\n",
        "            utility = evaluate_utility(model, val_loader, t.item())\n",
        "            if utility > best_epoch_utility:\n",
        "                best_epoch_utility = utility\n",
        "                best_epoch_threshold = t.item()\n",
        "\n",
        "    # ---------- LOGGING ----------\n",
        "    with open(LOG_PATH, \"a\", newline=\"\") as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow([\n",
        "            epoch + 1,\n",
        "            epoch_loss,\n",
        "            best_epoch_utility,\n",
        "            best_epoch_threshold\n",
        "        ])\n",
        "\n",
        "    print(\n",
        "        f\"Epoch [{epoch+1}/{NUM_EPOCHS}] | \"\n",
        "        f\"Train Loss: {epoch_loss:.2f} | \"\n",
        "        f\"Val Utility: {best_epoch_utility:.2f} | \"\n",
        "        f\"Best τ: {best_epoch_threshold:.2f}\"\n",
        "    )\n",
        "\n",
        "    # ---------- CHECKPOINTING ----------\n",
        "    if best_epoch_utility > best_utility:\n",
        "        best_utility = best_epoch_utility\n",
        "        epochs_no_improve = 0\n",
        "\n",
        "        torch.save(\n",
        "            {\n",
        "                \"epoch\": epoch + 1,\n",
        "                \"model_state\": model.state_dict(),\n",
        "                \"best_threshold\": best_epoch_threshold,\n",
        "                \"val_utility\": best_epoch_utility\n",
        "            },\n",
        "            BEST_MODEL_PATH\n",
        "        )\n",
        "\n",
        "        print(\"New best model saved\")\n",
        "\n",
        "    else:\n",
        "        epochs_no_improve += 1\n",
        "        print(f\"No improvement for {epochs_no_improve} epoch(s)\")\n",
        "\n",
        "    # ---------- EARLY STOPPING ----------\n",
        "    if epochs_no_improve >= PATIENCE_IMPROVED:\n",
        "        print(\"⏹ Early stopping triggered\")\n",
        "        break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3l9QbybbiZ2x",
        "outputId": "ac0a38c8-050f-4dc5-93a6-c5691c06d4bc"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NUM_FEATURES: 40\n",
            "Model checkpoints → /content/drive/MyDrive/Thesis/PhysionetSepsis/models/best_modelv3.pt\n",
            "Training log → /content/drive/MyDrive/Thesis/PhysionetSepsis/logs/training_logv3.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/60] | Train Loss: 188.78 | Val Utility: -3860.00 | Best τ: 0.35\n",
            "New best model saved\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/60] | Train Loss: 147.24 | Val Utility: -3689.50 | Best τ: 0.35\n",
            "New best model saved\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/60] | Train Loss: 134.02 | Val Utility: -2988.00 | Best τ: 0.50\n",
            "New best model saved\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/60] | Train Loss: 127.48 | Val Utility: -3056.00 | Best τ: 0.70\n",
            "No improvement for 1 epoch(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/60] | Train Loss: 121.52 | Val Utility: -2625.50 | Best τ: 0.60\n",
            "New best model saved\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/60] | Train Loss: 117.52 | Val Utility: -2044.50 | Best τ: 0.75\n",
            "New best model saved\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/60] | Train Loss: 113.84 | Val Utility: -2160.00 | Best τ: 0.30\n",
            "No improvement for 1 epoch(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/60] | Train Loss: 110.70 | Val Utility: -2853.00 | Best τ: 0.65\n",
            "No improvement for 2 epoch(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/60] | Train Loss: 107.12 | Val Utility: -2100.00 | Best τ: 0.55\n",
            "No improvement for 3 epoch(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/60] | Train Loss: 104.91 | Val Utility: -2035.00 | Best τ: 0.60\n",
            "New best model saved\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [11/60] | Train Loss: 102.64 | Val Utility: -1918.50 | Best τ: 0.60\n",
            "New best model saved\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [12/60] | Train Loss: 101.63 | Val Utility: -2143.50 | Best τ: 0.30\n",
            "No improvement for 1 epoch(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [13/60] | Train Loss: 99.65 | Val Utility: -2118.00 | Best τ: 0.80\n",
            "No improvement for 2 epoch(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [14/60] | Train Loss: 97.66 | Val Utility: -1451.50 | Best τ: 0.60\n",
            "New best model saved\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [15/60] | Train Loss: 95.89 | Val Utility: -1895.00 | Best τ: 0.50\n",
            "No improvement for 1 epoch(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [16/60] | Train Loss: 94.92 | Val Utility: -2275.50 | Best τ: 0.70\n",
            "No improvement for 2 epoch(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [17/60] | Train Loss: 94.27 | Val Utility: -1902.00 | Best τ: 0.60\n",
            "No improvement for 3 epoch(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [18/60] | Train Loss: 91.99 | Val Utility: -2087.50 | Best τ: 0.45\n",
            "No improvement for 4 epoch(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [19/60] | Train Loss: 91.08 | Val Utility: -1438.50 | Best τ: 0.50\n",
            "New best model saved\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [20/60] | Train Loss: 91.06 | Val Utility: -1691.50 | Best τ: 0.50\n",
            "No improvement for 1 epoch(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [21/60] | Train Loss: 86.51 | Val Utility: -1800.50 | Best τ: 0.80\n",
            "No improvement for 2 epoch(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [22/60] | Train Loss: 85.22 | Val Utility: -1351.50 | Best τ: 0.65\n",
            "New best model saved\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [23/60] | Train Loss: 84.89 | Val Utility: -1451.50 | Best τ: 0.60\n",
            "No improvement for 1 epoch(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [24/60] | Train Loss: 83.56 | Val Utility: -1839.00 | Best τ: 0.75\n",
            "No improvement for 2 epoch(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [25/60] | Train Loss: 81.42 | Val Utility: -1934.00 | Best τ: 0.60\n",
            "No improvement for 3 epoch(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [26/60] | Train Loss: 81.21 | Val Utility: -1655.50 | Best τ: 0.70\n",
            "No improvement for 4 epoch(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [27/60] | Train Loss: 79.54 | Val Utility: -2148.00 | Best τ: 0.50\n",
            "No improvement for 5 epoch(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [28/60] | Train Loss: 79.96 | Val Utility: -1509.50 | Best τ: 0.55\n",
            "No improvement for 6 epoch(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [29/60] | Train Loss: 76.88 | Val Utility: -2035.00 | Best τ: 0.40\n",
            "No improvement for 7 epoch(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [30/60] | Train Loss: 79.44 | Val Utility: -1852.50 | Best τ: 0.70\n",
            "No improvement for 8 epoch(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [31/60] | Train Loss: 76.88 | Val Utility: -1860.00 | Best τ: 0.35\n",
            "No improvement for 9 epoch(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [32/60] | Train Loss: 75.61 | Val Utility: -1349.00 | Best τ: 0.50\n",
            "New best model saved\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [33/60] | Train Loss: 73.68 | Val Utility: -1840.00 | Best τ: 0.50\n",
            "No improvement for 1 epoch(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [34/60] | Train Loss: 74.21 | Val Utility: -1801.50 | Best τ: 0.85\n",
            "No improvement for 2 epoch(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [35/60] | Train Loss: 70.85 | Val Utility: -1790.00 | Best τ: 0.75\n",
            "No improvement for 3 epoch(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [36/60] | Train Loss: 71.40 | Val Utility: -1930.00 | Best τ: 0.60\n",
            "No improvement for 4 epoch(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [37/60] | Train Loss: 69.36 | Val Utility: -1797.00 | Best τ: 0.35\n",
            "No improvement for 5 epoch(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [38/60] | Train Loss: 68.38 | Val Utility: -1514.50 | Best τ: 0.65\n",
            "No improvement for 6 epoch(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [39/60] | Train Loss: 68.98 | Val Utility: -1695.00 | Best τ: 0.35\n",
            "No improvement for 7 epoch(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [40/60] | Train Loss: 67.66 | Val Utility: -1814.50 | Best τ: 0.40\n",
            "No improvement for 8 epoch(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [41/60] | Train Loss: 67.02 | Val Utility: -1954.50 | Best τ: 0.75\n",
            "No improvement for 9 epoch(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [42/60] | Train Loss: 64.90 | Val Utility: -2036.00 | Best τ: 0.90\n",
            "No improvement for 10 epoch(s)\n",
            "⏹ Early stopping triggered\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **VALIDATION**"
      ],
      "metadata": {
        "id": "mmgf56P7ymbC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CELL A — Model Evaluation Utilities\n",
        "\n",
        "Purpose:\n",
        "Reusable functions for validation / test evaluation (no training logic)."
      ],
      "metadata": {
        "id": "DHL3VvlTyxEv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# -------------------------\n",
        "# Utility-based evaluation\n",
        "# -------------------------\n",
        "def evaluate_model_utility(model, dataloader, threshold):\n",
        "    model.eval()\n",
        "    total_utility = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, M, DT, Y, attn_mask in dataloader:\n",
        "            X = X.to(DEVICE)\n",
        "            M = M.to(DEVICE)\n",
        "            DT = DT.to(DEVICE)\n",
        "            Y = Y.to(DEVICE)\n",
        "            attn_mask = attn_mask.to(DEVICE)\n",
        "\n",
        "            logits = model(X, M, DT, attn_mask)\n",
        "            probs = torch.sigmoid(logits)\n",
        "            preds = (probs >= threshold).float()\n",
        "\n",
        "            for i in range(X.size(0)):\n",
        "                length = int(attn_mask[i].sum())\n",
        "                total_utility += physionet_utility(\n",
        "                    Y[i, :length].cpu().numpy(),\n",
        "                    preds[i, :length].cpu().numpy()\n",
        "                )\n",
        "\n",
        "    return total_utility\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# Accuracy (hour-level)\n",
        "# -------------------------\n",
        "def evaluate_model_accuracy(model, dataloader, threshold):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, M, DT, Y, attn_mask in dataloader:\n",
        "            X = X.to(DEVICE)\n",
        "            M = M.to(DEVICE)\n",
        "            DT = DT.to(DEVICE)\n",
        "            Y = Y.to(DEVICE)\n",
        "            attn_mask = attn_mask.to(DEVICE)\n",
        "\n",
        "            logits = model(X, M, DT, attn_mask)\n",
        "            probs = torch.sigmoid(logits)\n",
        "            preds = (probs >= threshold).float()\n",
        "\n",
        "            mask = attn_mask.bool()\n",
        "            correct += (preds[mask] == Y[mask]).sum().item()\n",
        "            total += mask.sum().item()\n",
        "\n",
        "    return correct / total\n"
      ],
      "metadata": {
        "id": "eSwnwXzUyvvC"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CELL B — Load & Evaluate a Single Model\n",
        "\n",
        "Purpose:\n",
        "Evaluate one checkpoint on validation or test."
      ],
      "metadata": {
        "id": "Ihw00fD_9Rs8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_checkpoint(checkpoint_path, dataloader, split_name=\"Validation\"):\n",
        "    print(f\"\\nEvaluating model: {checkpoint_path}\")\n",
        "\n",
        "    checkpoint = torch.load(checkpoint_path, map_location=DEVICE)\n",
        "\n",
        "    model = TemporalTransformer(NUM_FEATURES).to(DEVICE)\n",
        "    model.load_state_dict(checkpoint[\"model_state\"])\n",
        "\n",
        "    threshold = checkpoint[\"best_threshold\"]\n",
        "\n",
        "    utility = evaluate_model_utility(model, dataloader, threshold)\n",
        "    accuracy = evaluate_model_accuracy(model, dataloader, threshold)\n",
        "\n",
        "    print(f\"{split_name} Utility Score : {utility:.2f}\")\n",
        "    print(f\"{split_name} Accuracy      : {accuracy:.4f}\")\n",
        "\n",
        "    return {\n",
        "        \"path\": checkpoint_path,\n",
        "        \"threshold\": threshold,\n",
        "        \"utility\": utility,\n",
        "        \"accuracy\": accuracy\n",
        "    }\n"
      ],
      "metadata": {
        "id": "QJvsgoeV9SHw"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CELL C — Evaluate ALL Saved Models (Model Comparison)\n",
        "\n",
        "Purpose:\n",
        "Compare multiple saved models fairly and pick the best."
      ],
      "metadata": {
        "id": "mpY2vt6oy9Sz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------\n",
        "# Reconstruct NUM_FEATURES\n",
        "# ---------------------\n",
        "NUM_FEATURES = len(FEATURE_COLS)\n",
        "print(\"NUM_FEATURES:\", NUM_FEATURES)\n",
        "\n",
        "import glob\n",
        "import pandas as pd\n",
        "\n",
        "MODEL_DIR = \"/content/drive/MyDrive/Thesis/PhysionetSepsis/models\"\n",
        "\n",
        "model_paths = sorted(glob.glob(f\"{MODEL_DIR}/*.pt\"))\n",
        "print(f\"Found {len(model_paths)} models\")\n",
        "\n",
        "results = []\n",
        "\n",
        "for path in model_paths:\n",
        "    result = evaluate_checkpoint(\n",
        "        path,\n",
        "        val_loader,     # or test_loader\n",
        "        split_name=\"Validation\"\n",
        "    )\n",
        "    results.append(result)\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df = results_df.sort_values(\"utility\", ascending=False)\n",
        "\n",
        "results_df\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "id": "7XD4crqJy_M6",
        "outputId": "17bbec87-b03a-4a61-f060-1af6fddb8f44"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NUM_FEATURES: 40\n",
            "Found 4 models\n",
            "\n",
            "Evaluating model: /content/drive/MyDrive/Thesis/PhysionetSepsis/models/best_model1.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:515: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. We recommend specifying layout=torch.jagged when constructing a nested tensor, as this layout receives active development, has better operator coverage, and works with torch.compile. (Triggered internally at /pytorch/aten/src/ATen/NestedTensorImpl.cpp:178.)\n",
            "  output = torch._nested_tensor_from_mask(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Utility Score : -1477.50\n",
            "Validation Accuracy      : 0.9770\n",
            "\n",
            "Evaluating model: /content/drive/MyDrive/Thesis/PhysionetSepsis/models/best_model2.pt\n",
            "Validation Utility Score : -1361.50\n",
            "Validation Accuracy      : 0.9782\n",
            "\n",
            "Evaluating model: /content/drive/MyDrive/Thesis/PhysionetSepsis/models/best_modelv2.pt\n",
            "Validation Utility Score : -1627.50\n",
            "Validation Accuracy      : 0.9773\n",
            "\n",
            "Evaluating model: /content/drive/MyDrive/Thesis/PhysionetSepsis/models/best_modelv3.pt\n",
            "Validation Utility Score : -1349.00\n",
            "Validation Accuracy      : 0.9791\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                path  threshold  utility  \\\n",
              "3  /content/drive/MyDrive/Thesis/PhysionetSepsis/...       0.50  -1349.0   \n",
              "1  /content/drive/MyDrive/Thesis/PhysionetSepsis/...       0.70  -1361.5   \n",
              "0  /content/drive/MyDrive/Thesis/PhysionetSepsis/...       0.65  -1477.5   \n",
              "2  /content/drive/MyDrive/Thesis/PhysionetSepsis/...       0.80  -1627.5   \n",
              "\n",
              "   accuracy  \n",
              "3  0.979139  \n",
              "1  0.978156  \n",
              "0  0.976952  \n",
              "2  0.977315  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-23c202fb-dfeb-43f5-a58a-1418c49ca127\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>threshold</th>\n",
              "      <th>utility</th>\n",
              "      <th>accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/drive/MyDrive/Thesis/PhysionetSepsis/...</td>\n",
              "      <td>0.50</td>\n",
              "      <td>-1349.0</td>\n",
              "      <td>0.979139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/drive/MyDrive/Thesis/PhysionetSepsis/...</td>\n",
              "      <td>0.70</td>\n",
              "      <td>-1361.5</td>\n",
              "      <td>0.978156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/drive/MyDrive/Thesis/PhysionetSepsis/...</td>\n",
              "      <td>0.65</td>\n",
              "      <td>-1477.5</td>\n",
              "      <td>0.976952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/drive/MyDrive/Thesis/PhysionetSepsis/...</td>\n",
              "      <td>0.80</td>\n",
              "      <td>-1627.5</td>\n",
              "      <td>0.977315</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-23c202fb-dfeb-43f5-a58a-1418c49ca127')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-23c202fb-dfeb-43f5-a58a-1418c49ca127 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-23c202fb-dfeb-43f5-a58a-1418c49ca127');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-37cd88e1-004c-461a-bca3-c108edc513ed\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-37cd88e1-004c-461a-bca3-c108edc513ed')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-37cd88e1-004c-461a-bca3-c108edc513ed button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_0ad1873c-53a3-43ea-822e-f42ab8010952\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('results_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_0ad1873c-53a3-43ea-822e-f42ab8010952 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('results_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "results_df",
              "summary": "{\n  \"name\": \"results_df\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"/content/drive/MyDrive/Thesis/PhysionetSepsis/models/best_model2.pt\",\n          \"/content/drive/MyDrive/Thesis/PhysionetSepsis/models/best_modelv2.pt\",\n          \"/content/drive/MyDrive/Thesis/PhysionetSepsis/models/best_modelv3.pt\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"threshold\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.12499998211860694,\n        \"min\": 0.5,\n        \"max\": 0.7999999523162842,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.699999988079071,\n          0.7999999523162842,\n          0.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"utility\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 129.40335840567147,\n        \"min\": -1627.5,\n        \"max\": -1349.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          -1361.5,\n          -1627.5,\n          -1349.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0009729877358367799,\n        \"min\": 0.9769521491256166,\n        \"max\": 0.9791386415561677,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.978156428159631,\n          0.9773151410330323,\n          0.9791386415561677\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# GRID SEARCH: Temporal Smoothing Decision Logic (VALIDATION)\n",
        "# ============================================================\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "MODEL_PATH = \"/content/drive/MyDrive/Thesis/PhysionetSepsis/models/best_modelv3.pt\"\n",
        "DATALOADER = val_loader\n",
        "MC_SAMPLES = 10   # only for stability; no uncertainty gating yet\n",
        "\n",
        "# Search space (SAFE + EFFECTIVE)\n",
        "THRESHOLDS = [0.35, 0.40, 0.45]\n",
        "MIN_CONSECUTIVES = [2, 3]\n",
        "\n",
        "print(\"Evaluating model:\", MODEL_PATH)\n",
        "\n",
        "# -------------------------\n",
        "# Load model\n",
        "# -------------------------\n",
        "checkpoint = torch.load(MODEL_PATH, map_location=DEVICE)\n",
        "model = TemporalTransformer(NUM_FEATURES).to(DEVICE)\n",
        "model.load_state_dict(checkpoint[\"model_state\"])\n",
        "\n",
        "# -------------------------\n",
        "# Helpers\n",
        "# -------------------------\n",
        "def mc_mean_predict(model, X, M, DT, attn_mask, n_samples):\n",
        "    model.train()  # enable dropout (light MC averaging)\n",
        "    probs = []\n",
        "    with torch.no_grad():\n",
        "        for _ in range(n_samples):\n",
        "            logits = model(X, M, DT, attn_mask)\n",
        "            probs.append(torch.sigmoid(logits))\n",
        "    probs = torch.stack(probs, dim=0)\n",
        "    return probs.mean(dim=0)\n",
        "\n",
        "def temporal_smoothing(prob_seq, threshold, min_consecutive):\n",
        "    raw = (prob_seq >= threshold).astype(int)\n",
        "    smoothed = np.zeros_like(raw)\n",
        "    count = 0\n",
        "    for t in range(len(raw)):\n",
        "        if raw[t] == 1:\n",
        "            count += 1\n",
        "            if count >= min_consecutive:\n",
        "                smoothed[t] = 1\n",
        "        else:\n",
        "            count = 0\n",
        "    return smoothed\n",
        "\n",
        "# -------------------------\n",
        "# Grid search\n",
        "# -------------------------\n",
        "results = []\n",
        "\n",
        "for threshold in THRESHOLDS:\n",
        "    for min_c in MIN_CONSECUTIVES:\n",
        "        total_utility = 0.0\n",
        "\n",
        "        for X, M, DT, Y, attn_mask in DATALOADER:\n",
        "            X, M, DT, Y, attn_mask = (\n",
        "                X.to(DEVICE),\n",
        "                M.to(DEVICE),\n",
        "                DT.to(DEVICE),\n",
        "                Y.to(DEVICE),\n",
        "                attn_mask.to(DEVICE),\n",
        "            )\n",
        "\n",
        "            mean_prob = mc_mean_predict(\n",
        "                model, X, M, DT, attn_mask, MC_SAMPLES\n",
        "            )\n",
        "\n",
        "            for i in range(X.size(0)):\n",
        "                length = int(attn_mask[i].sum())\n",
        "                p = mean_prob[i, :length].cpu().numpy()\n",
        "                y = Y[i, :length].cpu().numpy()\n",
        "\n",
        "                preds = temporal_smoothing(\n",
        "                    p, threshold, min_c\n",
        "                )\n",
        "\n",
        "                total_utility += physionet_utility(y, preds)\n",
        "\n",
        "        results.append({\n",
        "            \"threshold\": threshold,\n",
        "            \"min_consecutive\": min_c,\n",
        "            \"utility\": total_utility\n",
        "        })\n",
        "\n",
        "        print(\n",
        "            f\"τ={threshold:.2f}, min_consec={min_c} → Utility={total_utility:.1f}\"\n",
        "        )\n",
        "\n",
        "# -------------------------\n",
        "# Results table\n",
        "# -------------------------\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df = results_df.sort_values(\"utility\", ascending=False)\n",
        "\n",
        "print(\"\\n===== GRID SEARCH RESULTS (BEST FIRST) =====\")\n",
        "results_df\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "kp2-gkPB1xHZ",
        "outputId": "d4bfa8c8-4a0f-40fb-bc88-dc71408231fc"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating model: /content/drive/MyDrive/Thesis/PhysionetSepsis/models/best_modelv3.pt\n",
            "τ=0.35, min_consec=2 → Utility=-913.0\n",
            "τ=0.35, min_consec=3 → Utility=-1267.0\n",
            "τ=0.40, min_consec=2 → Utility=-940.0\n",
            "τ=0.40, min_consec=3 → Utility=-1353.0\n",
            "τ=0.45, min_consec=2 → Utility=-1065.0\n",
            "τ=0.45, min_consec=3 → Utility=-1524.5\n",
            "\n",
            "===== GRID SEARCH RESULTS (BEST FIRST) =====\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   threshold  min_consecutive  utility\n",
              "0       0.35                2   -913.0\n",
              "2       0.40                2   -940.0\n",
              "4       0.45                2  -1065.0\n",
              "1       0.35                3  -1267.0\n",
              "3       0.40                3  -1353.0\n",
              "5       0.45                3  -1524.5"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f37e03f1-b784-4431-a396-5dccbfc3612e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>threshold</th>\n",
              "      <th>min_consecutive</th>\n",
              "      <th>utility</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.35</td>\n",
              "      <td>2</td>\n",
              "      <td>-913.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.40</td>\n",
              "      <td>2</td>\n",
              "      <td>-940.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.45</td>\n",
              "      <td>2</td>\n",
              "      <td>-1065.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.35</td>\n",
              "      <td>3</td>\n",
              "      <td>-1267.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.40</td>\n",
              "      <td>3</td>\n",
              "      <td>-1353.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.45</td>\n",
              "      <td>3</td>\n",
              "      <td>-1524.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f37e03f1-b784-4431-a396-5dccbfc3612e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f37e03f1-b784-4431-a396-5dccbfc3612e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f37e03f1-b784-4431-a396-5dccbfc3612e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-69c5643f-526f-4159-9786-7a4a1fe995d5\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-69c5643f-526f-4159-9786-7a4a1fe995d5')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-69c5643f-526f-4159-9786-7a4a1fe995d5 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_9567bfd4-4452-4cae-88ed-9a5fa1351ad9\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('results_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_9567bfd4-4452-4cae-88ed-9a5fa1351ad9 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('results_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "results_df",
              "summary": "{\n  \"name\": \"results_df\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"threshold\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0447213595499958,\n        \"min\": 0.35,\n        \"max\": 0.45,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.35,\n          0.4,\n          0.45\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"min_consecutive\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 2,\n        \"max\": 3,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          3,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"utility\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 244.22989511250802,\n        \"min\": -1524.5,\n        \"max\": -913.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          -913.0,\n          -940.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CELL D — Select BEST Model for Final Test Evaluation\n",
        "\n",
        "Purpose:\n",
        "Lock in the best validation model and evaluate on test set."
      ],
      "metadata": {
        "id": "xYc9f4xMzDEc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# SAFE EVALUATION: Temporal Smoothing ONLY (no uncertainty yet)\n",
        "# ============================================================\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "MODEL_PATH = \"/content/drive/MyDrive/Thesis/PhysionetSepsis/models/best_modelv3.pt\"\n",
        "DATALOADER = val_loader\n",
        "MIN_CONSECUTIVE = 2\n",
        "MC_SAMPLES = 10\n",
        "\n",
        "checkpoint = torch.load(MODEL_PATH, map_location=DEVICE)\n",
        "model = TemporalTransformer(NUM_FEATURES).to(DEVICE)\n",
        "model.load_state_dict(checkpoint[\"model_state\"])\n",
        "\n",
        "# LOWER threshold because smoothing already increases precision\n",
        "threshold = max(0.35, checkpoint[\"best_threshold\"] - 0.1)\n",
        "\n",
        "print(\"Using threshold:\", threshold)\n",
        "\n",
        "def mc_dropout_predict(model, X, M, DT, attn_mask, n_samples):\n",
        "    model.train()\n",
        "    probs = []\n",
        "    with torch.no_grad():\n",
        "        for _ in range(n_samples):\n",
        "            logits = model(X, M, DT, attn_mask)\n",
        "            probs.append(torch.sigmoid(logits))\n",
        "    probs = torch.stack(probs, dim=0)\n",
        "    return probs.mean(dim=0)\n",
        "\n",
        "def temporal_smoothing(prob_seq, threshold, min_consecutive):\n",
        "    raw = (prob_seq >= threshold).astype(int)\n",
        "    smoothed = np.zeros_like(raw)\n",
        "    count = 0\n",
        "    for t in range(len(raw)):\n",
        "        if raw[t] == 1:\n",
        "            count += 1\n",
        "            if count >= min_consecutive:\n",
        "                smoothed[t] = 1\n",
        "        else:\n",
        "            count = 0\n",
        "    return smoothed\n",
        "\n",
        "total_utility = 0.0\n",
        "\n",
        "for X, M, DT, Y, attn_mask in DATALOADER:\n",
        "    X, M, DT, Y, attn_mask = (\n",
        "        X.to(DEVICE),\n",
        "        M.to(DEVICE),\n",
        "        DT.to(DEVICE),\n",
        "        Y.to(DEVICE),\n",
        "        attn_mask.to(DEVICE),\n",
        "    )\n",
        "\n",
        "    mean_prob = mc_dropout_predict(model, X, M, DT, attn_mask, MC_SAMPLES)\n",
        "\n",
        "    for i in range(X.size(0)):\n",
        "        length = int(attn_mask[i].sum())\n",
        "        p = mean_prob[i, :length].cpu().numpy()\n",
        "        y = Y[i, :length].cpu().numpy()\n",
        "\n",
        "        preds = temporal_smoothing(p, threshold, MIN_CONSECUTIVE)\n",
        "        total_utility += physionet_utility(y, preds)\n",
        "\n",
        "print(\"SMOOTHED UTILITY SCORE:\", total_utility)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osGAztfTzDlL",
        "outputId": "ef7a42ba-67e0-4ad1-a83c-72f052e4115c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using threshold: 0.4\n",
            "SMOOTHED UTILITY SCORE: -917.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# FINAL TEST EVALUATION (LOCKED CONFIGURATION)\n",
        "# ============================================================\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# -------------------------\n",
        "# LOCKED CONFIGURATION\n",
        "# -------------------------\n",
        "MODEL_PATH = \"/content/drive/MyDrive/Thesis/PhysionetSepsis/models/best_modelv3.pt\"\n",
        "DATALOADER = test_loader     # FINAL evaluation only\n",
        "THRESHOLD = 0.35             # LOCKED from validation\n",
        "MIN_CONSECUTIVE = 2          # LOCKED from validation\n",
        "MC_SAMPLES = 10              # light MC averaging (no uncertainty gating)\n",
        "\n",
        "print(\"FINAL TEST EVALUATION\")\n",
        "print(\"Model:\", MODEL_PATH)\n",
        "print(\"Threshold:\", THRESHOLD)\n",
        "print(\"Min consecutive hours:\", MIN_CONSECUTIVE)\n",
        "\n",
        "# -------------------------\n",
        "# Load model\n",
        "# -------------------------\n",
        "checkpoint = torch.load(MODEL_PATH, map_location=DEVICE)\n",
        "\n",
        "model = TemporalTransformer(NUM_FEATURES).to(DEVICE)\n",
        "model.load_state_dict(checkpoint[\"model_state\"])\n",
        "\n",
        "# -------------------------\n",
        "# Helpers\n",
        "# -------------------------\n",
        "def mc_mean_predict(model, X, M, DT, attn_mask, n_samples):\n",
        "    model.train()  # enable dropout\n",
        "    probs = []\n",
        "    with torch.no_grad():\n",
        "        for _ in range(n_samples):\n",
        "            logits = model(X, M, DT, attn_mask)\n",
        "            probs.append(torch.sigmoid(logits))\n",
        "    probs = torch.stack(probs, dim=0)\n",
        "    return probs.mean(dim=0)\n",
        "\n",
        "def temporal_smoothing(prob_seq, threshold, min_consecutive):\n",
        "    raw = (prob_seq >= threshold).astype(int)\n",
        "    smoothed = np.zeros_like(raw)\n",
        "    count = 0\n",
        "    for t in range(len(raw)):\n",
        "        if raw[t] == 1:\n",
        "            count += 1\n",
        "            if count >= min_consecutive:\n",
        "                smoothed[t] = 1\n",
        "        else:\n",
        "            count = 0\n",
        "    return smoothed\n",
        "\n",
        "# -------------------------\n",
        "# Evaluation\n",
        "# -------------------------\n",
        "total_utility = 0.0\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "for X, M, DT, Y, attn_mask in DATALOADER:\n",
        "    X = X.to(DEVICE)\n",
        "    M = M.to(DEVICE)\n",
        "    DT = DT.to(DEVICE)\n",
        "    Y = Y.to(DEVICE)\n",
        "    attn_mask = attn_mask.to(DEVICE)\n",
        "\n",
        "    mean_prob = mc_mean_predict(\n",
        "        model, X, M, DT, attn_mask, MC_SAMPLES\n",
        "    )\n",
        "\n",
        "    for i in range(X.size(0)):\n",
        "        length = int(attn_mask[i].sum())\n",
        "\n",
        "        p = mean_prob[i, :length].cpu().numpy()\n",
        "        y = Y[i, :length].cpu().numpy()\n",
        "\n",
        "        preds = temporal_smoothing(\n",
        "            p, THRESHOLD, MIN_CONSECUTIVE\n",
        "        )\n",
        "\n",
        "        # Utility (PRIMARY METRIC)\n",
        "        total_utility += physionet_utility(y, preds)\n",
        "\n",
        "        # Accuracy (SECONDARY)\n",
        "        correct += (preds == y).sum()\n",
        "        total += len(y)\n",
        "\n",
        "# -------------------------\n",
        "# FINAL RESULTS\n",
        "# -------------------------\n",
        "accuracy = correct / total\n",
        "\n",
        "print(\"--------------------------------------------------\")\n",
        "print(\"FINAL TEST RESULTS\")\n",
        "print(\"PhysioNet Utility Score :\", total_utility)\n",
        "print(\"Hourly Accuracy         :\", round(accuracy, 4))\n",
        "print(\"--------------------------------------------------\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJDqIXLw2YqE",
        "outputId": "90e10259-39dc-4160-9188-6a7e6b66b290"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FINAL TEST EVALUATION\n",
            "Model: /content/drive/MyDrive/Thesis/PhysionetSepsis/models/best_modelv3.pt\n",
            "Threshold: 0.35\n",
            "Min consecutive hours: 2\n",
            "--------------------------------------------------\n",
            "FINAL TEST RESULTS\n",
            "PhysioNet Utility Score : -1379.0\n",
            "Hourly Accuracy         : 0.98\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "New Trial Test Evaluation (FAIL)"
      ],
      "metadata": {
        "id": "6oNoijfY5mzM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# SAFE UPGRADE: Smoothing + Alarm Persistence + Soft Uncertainty\n",
        "# FINAL TEST EVALUATION (NO RETRAINING)\n",
        "# ============================================================\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# -------------------------\n",
        "# LOCKED CONFIGURATION\n",
        "# -------------------------\n",
        "MODEL_PATH = \"/content/drive/MyDrive/Thesis/PhysionetSepsis/models/best_modelv3.pt\"\n",
        "DATALOADER = test_loader          # FINAL test set\n",
        "THRESHOLD = 0.35                 # validated\n",
        "MIN_CONSECUTIVE = 2              # validated\n",
        "MC_SAMPLES = 10                  # MC Dropout samples\n",
        "UNCERTAINTY_ALPHA = 10.0         # soft attenuation strength (SAFE range: 5–15)\n",
        "\n",
        "print(\"SAFE UPGRADE — FINAL TEST EVALUATION\")\n",
        "print(\"Model:\", MODEL_PATH)\n",
        "print(\"Threshold:\", THRESHOLD)\n",
        "print(\"Min consecutive:\", MIN_CONSECUTIVE)\n",
        "print(\"Uncertainty alpha:\", UNCERTAINTY_ALPHA)\n",
        "\n",
        "# -------------------------\n",
        "# Load model\n",
        "# -------------------------\n",
        "checkpoint = torch.load(MODEL_PATH, map_location=DEVICE)\n",
        "model = TemporalTransformer(NUM_FEATURES).to(DEVICE)\n",
        "model.load_state_dict(checkpoint[\"model_state\"])\n",
        "\n",
        "# -------------------------\n",
        "# Helpers\n",
        "# -------------------------\n",
        "def mc_mean_and_var(model, X, M, DT, attn_mask, n_samples):\n",
        "    model.train()  # enable dropout\n",
        "    probs = []\n",
        "    with torch.no_grad():\n",
        "        for _ in range(n_samples):\n",
        "            logits = model(X, M, DT, attn_mask)\n",
        "            probs.append(torch.sigmoid(logits))\n",
        "    probs = torch.stack(probs, dim=0)\n",
        "    return probs.mean(dim=0), probs.var(dim=0)\n",
        "\n",
        "def temporal_smoothing(prob_seq, threshold, min_consecutive):\n",
        "    raw = (prob_seq >= threshold).astype(int)\n",
        "    smoothed = np.zeros_like(raw)\n",
        "    count = 0\n",
        "    for t in range(len(raw)):\n",
        "        if raw[t] == 1:\n",
        "            count += 1\n",
        "            if count >= min_consecutive:\n",
        "                smoothed[t] = 1\n",
        "        else:\n",
        "            count = 0\n",
        "    return smoothed\n",
        "\n",
        "def persist_alarm(preds):\n",
        "    \"\"\"\n",
        "    Once alarm turns ON, keep it ON for the rest of the stay.\n",
        "    \"\"\"\n",
        "    if preds.sum() == 0:\n",
        "        return preds\n",
        "    first_on = np.argmax(preds == 1)\n",
        "    preds[first_on:] = 1\n",
        "    return preds\n",
        "\n",
        "# -------------------------\n",
        "# Evaluation\n",
        "# -------------------------\n",
        "total_utility = 0.0\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "for X, M, DT, Y, attn_mask in DATALOADER:\n",
        "    X, M, DT, Y, attn_mask = (\n",
        "        X.to(DEVICE),\n",
        "        M.to(DEVICE),\n",
        "        DT.to(DEVICE),\n",
        "        Y.to(DEVICE),\n",
        "        attn_mask.to(DEVICE),\n",
        "    )\n",
        "\n",
        "    mean_prob, var_prob = mc_mean_and_var(\n",
        "        model, X, M, DT, attn_mask, MC_SAMPLES\n",
        "    )\n",
        "\n",
        "    for i in range(X.size(0)):\n",
        "        length = int(attn_mask[i].sum())\n",
        "\n",
        "        p = mean_prob[i, :length].cpu().numpy()\n",
        "        v = var_prob[i, :length].cpu().numpy()\n",
        "        y = Y[i, :length].cpu().numpy()\n",
        "\n",
        "        # -------------------------\n",
        "        # Soft uncertainty attenuation\n",
        "        # -------------------------\n",
        "        # High variance → probability softly reduced, not zeroed\n",
        "        p = p * np.exp(-UNCERTAINTY_ALPHA * v)\n",
        "\n",
        "        # -------------------------\n",
        "        # Temporal smoothing\n",
        "        # -------------------------\n",
        "        preds = temporal_smoothing(\n",
        "            p, THRESHOLD, MIN_CONSECUTIVE\n",
        "        )\n",
        "\n",
        "        # -------------------------\n",
        "        # Alarm persistence\n",
        "        # -------------------------\n",
        "        preds = persist_alarm(preds)\n",
        "\n",
        "        # -------------------------\n",
        "        # Metrics\n",
        "        # -------------------------\n",
        "        total_utility += physionet_utility(y, preds)\n",
        "        correct += (preds == y).sum()\n",
        "        total += len(y)\n",
        "\n",
        "# -------------------------\n",
        "# FINAL RESULTS\n",
        "# -------------------------\n",
        "accuracy = correct / total\n",
        "\n",
        "print(\"--------------------------------------------------\")\n",
        "print(\"SAFE UPGRADE — FINAL TEST RESULTS\")\n",
        "print(\"PhysioNet Utility Score :\", total_utility)\n",
        "print(\"Hourly Accuracy         :\", round(accuracy, 4))\n",
        "print(\"--------------------------------------------------\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJCMw86Q5qLM",
        "outputId": "71138f10-172f-4951-818f-7967f34ee664"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SAFE UPGRADE — FINAL TEST EVALUATION\n",
            "Model: /content/drive/MyDrive/Thesis/PhysionetSepsis/models/best_modelv3.pt\n",
            "Threshold: 0.35\n",
            "Min consecutive: 2\n",
            "Uncertainty alpha: 10.0\n",
            "--------------------------------------------------\n",
            "SAFE UPGRADE — FINAL TEST RESULTS\n",
            "PhysioNet Utility Score : -2084.5\n",
            "Hourly Accuracy         : 0.9836\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RETRIAN NEW **MODEL**"
      ],
      "metadata": {
        "id": "-a2c3XFo6H0-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# UTILITY-AWARE RETRAINING (SAME ARCH + DATA)\n",
        "# Time-Weighted BCE to Encourage EARLIER Detection\n",
        "# ============================================================\n",
        "\n",
        "import os\n",
        "import csv\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from torch.amp import autocast, GradScaler\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ---------------------\n",
        "# Safety: reconstruct NUM_FEATURES\n",
        "# ---------------------\n",
        "NUM_FEATURES = len(FEATURE_COLS)\n",
        "print(\"NUM_FEATURES:\", NUM_FEATURES)\n",
        "\n",
        "# ---------------------\n",
        "# Directories (Google Drive)\n",
        "# ---------------------\n",
        "BASE_DIR = \"/content/drive/MyDrive/Thesis/PhysionetSepsis\"\n",
        "MODEL_DIR = os.path.join(BASE_DIR, \"models\")\n",
        "LOG_DIR = os.path.join(BASE_DIR, \"logs\")\n",
        "os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "os.makedirs(LOG_DIR, exist_ok=True)\n",
        "\n",
        "BEST_MODEL_PATH = os.path.join(MODEL_DIR, \"best_model_v4_time_weighted.pt\")\n",
        "LOG_PATH = os.path.join(LOG_DIR, \"training_log_v4_time_weighted.csv\")\n",
        "\n",
        "print(\"Model →\", BEST_MODEL_PATH)\n",
        "print(\"Log   →\", LOG_PATH)\n",
        "\n",
        "# ---------------------\n",
        "# Hyperparameters (SAFE, TARGETED)\n",
        "# ---------------------\n",
        "POS_WEIGHT = 6.5        # mild recall bias (do NOT go aggressive)\n",
        "PRE_WINDOW = 6          # hours before onset emphasized\n",
        "ALPHA = 2.0             # strength of early bias (start at 2.0)\n",
        "PATIENCE = 10           # utility is noisy\n",
        "THRESHOLDS = torch.linspace(0.3, 0.9, 13)  # narrower, FP-aware\n",
        "\n",
        "# ---------------------\n",
        "# Model / Optimizer / AMP\n",
        "# ---------------------\n",
        "model = TemporalTransformer(NUM_FEATURES).to(DEVICE)\n",
        "\n",
        "optimizer = torch.optim.AdamW(\n",
        "    model.parameters(),\n",
        "    lr=LEARNING_RATE,\n",
        "    weight_decay=WEIGHT_DECAY\n",
        ")\n",
        "\n",
        "scaler = GradScaler(enabled=USE_AMP)\n",
        "\n",
        "# ---------------------\n",
        "# Time-Weighted Masked BCE\n",
        "# ---------------------\n",
        "def time_weighted_masked_bce(\n",
        "    logits, y, attn_mask, onset_idx,\n",
        "    pos_weight=6.5, pre_window=6, alpha=2.0\n",
        "):\n",
        "    \"\"\"\n",
        "    logits: (B, T)\n",
        "    y: (B, T)\n",
        "    attn_mask: (B, T)\n",
        "    onset_idx: (B,) int, -1 if non-septic\n",
        "    \"\"\"\n",
        "    B, T = y.shape\n",
        "    device = y.device\n",
        "\n",
        "    pw = torch.tensor(pos_weight, device=device)\n",
        "    bce = F.binary_cross_entropy_with_logits(\n",
        "        logits, y, reduction=\"none\", pos_weight=pw\n",
        "    )\n",
        "\n",
        "    # Time weights (default 1)\n",
        "    time_w = torch.ones_like(bce)\n",
        "\n",
        "    for i in range(B):\n",
        "        oi = onset_idx[i].item()\n",
        "        if oi >= 0:\n",
        "            t = torch.arange(T, device=device)\n",
        "            pre = (t <= oi)\n",
        "            dist = (oi - t).clamp(min=0)\n",
        "            ramp = 1.0 + alpha * (1.0 - (dist / pre_window).clamp(0, 1))\n",
        "            time_w[i, pre] = ramp[pre]\n",
        "\n",
        "    loss = bce * time_w * attn_mask\n",
        "    return loss.sum() / attn_mask.sum().clamp_min(1)\n",
        "\n",
        "# ---------------------\n",
        "# Init CSV log\n",
        "# ---------------------\n",
        "with open(LOG_PATH, \"w\", newline=\"\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([\"epoch\", \"train_loss\", \"val_utility\", \"best_threshold\"])\n",
        "\n",
        "# ---------------------\n",
        "# Early stopping\n",
        "# ---------------------\n",
        "best_utility = -float(\"inf\")\n",
        "epochs_no_improve = 0\n",
        "\n",
        "# ============================================================\n",
        "# TRAINING LOOP\n",
        "# ============================================================\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    model.train()\n",
        "    epoch_loss = 0.0\n",
        "\n",
        "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS}\", leave=False)\n",
        "\n",
        "    for X, M, DT, Y, attn_mask in pbar:\n",
        "        X = X.to(DEVICE)\n",
        "        M = M.to(DEVICE)\n",
        "        DT = DT.to(DEVICE)\n",
        "        Y = Y.to(DEVICE)\n",
        "        attn_mask = attn_mask.to(DEVICE)\n",
        "\n",
        "        # Onset index per patient (first positive hour), -1 if none\n",
        "        onset_idx = torch.full((Y.size(0),), -1, device=Y.device)\n",
        "        for i in range(Y.size(0)):\n",
        "            pos = torch.where(Y[i] == 1)[0]\n",
        "            if len(pos) > 0:\n",
        "                onset_idx[i] = pos[0]\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "        with autocast(device_type=\"cuda\", enabled=USE_AMP):\n",
        "            logits = model(X, M, DT, attn_mask)\n",
        "            loss = time_weighted_masked_bce(\n",
        "                logits, Y, attn_mask, onset_idx,\n",
        "                pos_weight=POS_WEIGHT,\n",
        "                pre_window=PRE_WINDOW,\n",
        "                alpha=ALPHA\n",
        "            )\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.unscale_(optimizer)\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), MAX_GRAD_NORM)\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        pbar.set_postfix(avg_loss=f\"{epoch_loss / (pbar.n + 1):.4f}\")\n",
        "\n",
        "    # ---------------------\n",
        "    # VALIDATION (UTILITY)\n",
        "    # ---------------------\n",
        "    model.eval()\n",
        "    best_epoch_utility = -float(\"inf\")\n",
        "    best_epoch_threshold = None\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for t in THRESHOLDS:\n",
        "            util = evaluate_utility(model, val_loader, t.item())\n",
        "            if util > best_epoch_utility:\n",
        "                best_epoch_utility = util\n",
        "                best_epoch_threshold = t.item()\n",
        "\n",
        "    # ---------------------\n",
        "    # LOGGING\n",
        "    # ---------------------\n",
        "    with open(LOG_PATH, \"a\", newline=\"\") as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow([\n",
        "            epoch + 1,\n",
        "            round(epoch_loss, 4),\n",
        "            round(best_epoch_utility, 4),\n",
        "            best_epoch_threshold\n",
        "        ])\n",
        "\n",
        "    print(\n",
        "        f\"Epoch [{epoch+1}/{NUM_EPOCHS}] | \"\n",
        "        f\"Train Loss: {epoch_loss:.2f} | \"\n",
        "        f\"Val Utility: {best_epoch_utility:.2f} | \"\n",
        "        f\"Best τ: {best_epoch_threshold:.2f}\"\n",
        "    )\n",
        "\n",
        "    # ---------------------\n",
        "    # CHECKPOINTING\n",
        "    # ---------------------\n",
        "    if best_epoch_utility > best_utility:\n",
        "        best_utility = best_epoch_utility\n",
        "        epochs_no_improve = 0\n",
        "        torch.save(\n",
        "            {\n",
        "                \"epoch\": epoch + 1,\n",
        "                \"model_state\": model.state_dict(),\n",
        "                \"best_threshold\": best_epoch_threshold,\n",
        "                \"val_utility\": best_epoch_utility,\n",
        "                \"pos_weight\": POS_WEIGHT,\n",
        "                \"pre_window\": PRE_WINDOW,\n",
        "                \"alpha\": ALPHA\n",
        "            },\n",
        "            BEST_MODEL_PATH\n",
        "        )\n",
        "        print(\"✓ New best model saved\")\n",
        "    else:\n",
        "        epochs_no_improve += 1\n",
        "        print(f\"No improvement for {epochs_no_improve} epoch(s)\")\n",
        "\n",
        "    if epochs_no_improve >= PATIENCE:\n",
        "        print(\"⏹ Early stopping triggered\")\n",
        "        break\n",
        "\n",
        "print(\"Training complete. Best model saved to:\")\n",
        "print(BEST_MODEL_PATH)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nt1OCEd6FWf",
        "outputId": "7d2dda5a-f45c-4ab3-ec75-c443610168d5"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NUM_FEATURES: 40\n",
            "Model → /content/drive/MyDrive/Thesis/PhysionetSepsis/models/best_model_v4_time_weighted.pt\n",
            "Log   → /content/drive/MyDrive/Thesis/PhysionetSepsis/logs/training_log_v4_time_weighted.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/60] | Train Loss: 238.47 | Val Utility: -4190.50 | Best τ: 0.45\n",
            "✓ New best model saved\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/60] | Train Loss: 188.62 | Val Utility: -4334.00 | Best τ: 0.75\n",
            "No improvement for 1 epoch(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/60] | Train Loss: 171.35 | Val Utility: -3497.50 | Best τ: 0.70\n",
            "✓ New best model saved\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/60] | Train Loss: 163.80 | Val Utility: -2600.50 | Best τ: 0.60\n",
            "✓ New best model saved\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/60] | Train Loss: 158.85 | Val Utility: -2952.50 | Best τ: 0.55\n",
            "No improvement for 1 epoch(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/60] | Train Loss: 155.83 | Val Utility: -2363.50 | Best τ: 0.75\n",
            "✓ New best model saved\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/60] | Train Loss: 147.04 | Val Utility: -2518.50 | Best τ: 0.65\n",
            "No improvement for 1 epoch(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/60] | Train Loss: 143.36 | Val Utility: -2093.00 | Best τ: 0.80\n",
            "✓ New best model saved\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/60] | Train Loss: 141.12 | Val Utility: -1609.00 | Best τ: 0.85\n",
            "✓ New best model saved\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/60] | Train Loss: 135.33 | Val Utility: -2215.00 | Best τ: 0.70\n",
            "No improvement for 1 epoch(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [11/60] | Train Loss: 135.40 | Val Utility: -2116.00 | Best τ: 0.60\n",
            "No improvement for 2 epoch(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [12/60] | Train Loss: 130.86 | Val Utility: -2185.00 | Best τ: 0.60\n",
            "No improvement for 3 epoch(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [13/60] | Train Loss: 131.29 | Val Utility: -1766.00 | Best τ: 0.75\n",
            "No improvement for 4 epoch(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [14/60] | Train Loss: 129.99 | Val Utility: -1368.00 | Best τ: 0.75\n",
            "✓ New best model saved\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [15/60] | Train Loss: 126.52 | Val Utility: -2282.50 | Best τ: 0.75\n",
            "No improvement for 1 epoch(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [16/60] | Train Loss: 124.07 | Val Utility: -1790.00 | Best τ: 0.80\n",
            "No improvement for 2 epoch(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [17/60] | Train Loss: 122.93 | Val Utility: -1696.00 | Best τ: 0.75\n",
            "No improvement for 3 epoch(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [18/60] | Train Loss: 121.84 | Val Utility: -1757.00 | Best τ: 0.65\n",
            "No improvement for 4 epoch(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [19/60] | Train Loss: 121.38 | Val Utility: -1752.00 | Best τ: 0.65\n",
            "No improvement for 5 epoch(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [20/60] | Train Loss: 119.08 | Val Utility: -1830.00 | Best τ: 0.75\n",
            "No improvement for 6 epoch(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [21/60] | Train Loss: 118.97 | Val Utility: -1618.00 | Best τ: 0.70\n",
            "No improvement for 7 epoch(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [22/60] | Train Loss: 114.79 | Val Utility: -1498.00 | Best τ: 0.75\n",
            "No improvement for 8 epoch(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [23/60] | Train Loss: 113.71 | Val Utility: -1861.50 | Best τ: 0.65\n",
            "No improvement for 9 epoch(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [24/60] | Train Loss: 111.32 | Val Utility: -1600.50 | Best τ: 0.60\n",
            "No improvement for 10 epoch(s)\n",
            "⏹ Early stopping triggered\n",
            "Training complete. Best model saved to:\n",
            "/content/drive/MyDrive/Thesis/PhysionetSepsis/models/best_model_v4_time_weighted.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "v4 Validation"
      ],
      "metadata": {
        "id": "9BIMT-DcAmN2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# VALIDATION — v4 TIME-WEIGHTED MODEL\n",
        "# Policy Selection (Threshold + Smoothing)\n",
        "# ============================================================\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "MODEL_PATH = \"/content/drive/MyDrive/Thesis/PhysionetSepsis/models/best_model_v4_time_weighted.pt\"\n",
        "DATALOADER = val_loader\n",
        "MC_SAMPLES = 10\n",
        "\n",
        "THRESHOLDS = [0.30, 0.35, 0.40]\n",
        "MIN_CONSECUTIVES = [2, 3]\n",
        "\n",
        "print(\"Validating model:\", MODEL_PATH)\n",
        "\n",
        "# -------------------------\n",
        "# Load model\n",
        "# -------------------------\n",
        "checkpoint = torch.load(MODEL_PATH, map_location=DEVICE)\n",
        "model = TemporalTransformer(NUM_FEATURES).to(DEVICE)\n",
        "model.load_state_dict(checkpoint[\"model_state\"])\n",
        "\n",
        "# -------------------------\n",
        "# Helpers\n",
        "# -------------------------\n",
        "def mc_mean_predict(model, X, M, DT, attn_mask, n_samples):\n",
        "    model.train()  # enable dropout\n",
        "    probs = []\n",
        "    with torch.no_grad():\n",
        "        for _ in range(n_samples):\n",
        "            logits = model(X, M, DT, attn_mask)\n",
        "            probs.append(torch.sigmoid(logits))\n",
        "    return torch.stack(probs, dim=0).mean(dim=0)\n",
        "\n",
        "def temporal_smoothing(prob_seq, threshold, min_consecutive):\n",
        "    raw = (prob_seq >= threshold).astype(int)\n",
        "    smoothed = np.zeros_like(raw)\n",
        "    count = 0\n",
        "    for t in range(len(raw)):\n",
        "        if raw[t] == 1:\n",
        "            count += 1\n",
        "            if count >= min_consecutive:\n",
        "                smoothed[t] = 1\n",
        "        else:\n",
        "            count = 0\n",
        "    return smoothed\n",
        "\n",
        "# -------------------------\n",
        "# Grid search\n",
        "# -------------------------\n",
        "results = []\n",
        "\n",
        "for tau in THRESHOLDS:\n",
        "    for min_c in MIN_CONSECUTIVES:\n",
        "        total_utility = 0.0\n",
        "\n",
        "        for X, M, DT, Y, attn_mask in DATALOADER:\n",
        "            X, M, DT, Y, attn_mask = (\n",
        "                X.to(DEVICE),\n",
        "                M.to(DEVICE),\n",
        "                DT.to(DEVICE),\n",
        "                Y.to(DEVICE),\n",
        "                attn_mask.to(DEVICE),\n",
        "            )\n",
        "\n",
        "            mean_prob = mc_mean_predict(\n",
        "                model, X, M, DT, attn_mask, MC_SAMPLES\n",
        "            )\n",
        "\n",
        "            for i in range(X.size(0)):\n",
        "                length = int(attn_mask[i].sum())\n",
        "                p = mean_prob[i, :length].cpu().numpy()\n",
        "                y = Y[i, :length].cpu().numpy()\n",
        "\n",
        "                preds = temporal_smoothing(p, tau, min_c)\n",
        "                total_utility += physionet_utility(y, preds)\n",
        "\n",
        "        results.append({\n",
        "            \"threshold\": tau,\n",
        "            \"min_consecutive\": min_c,\n",
        "            \"utility\": total_utility\n",
        "        })\n",
        "\n",
        "        print(f\"τ={tau:.2f}, min_consec={min_c} → Utility={total_utility:.1f}\")\n",
        "\n",
        "# -------------------------\n",
        "# Results table\n",
        "# -------------------------\n",
        "results_df = pd.DataFrame(results).sort_values(\"utility\", ascending=False)\n",
        "print(\"\\n===== VALIDATION RESULTS (BEST FIRST) =====\")\n",
        "results_df\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "lhjM9J2NAntO",
        "outputId": "b08d7abd-1a56-4a9b-d573-4cc392d2669a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validating model: /content/drive/MyDrive/Thesis/PhysionetSepsis/models/best_model_v4_time_weighted.pt\n",
            "τ=0.30, min_consec=2 → Utility=-1243.0\n",
            "τ=0.30, min_consec=3 → Utility=-1270.5\n",
            "τ=0.35, min_consec=2 → Utility=-1068.5\n",
            "τ=0.35, min_consec=3 → Utility=-1243.0\n",
            "τ=0.40, min_consec=2 → Utility=-967.5\n",
            "τ=0.40, min_consec=3 → Utility=-1220.0\n",
            "\n",
            "===== VALIDATION RESULTS (BEST FIRST) =====\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   threshold  min_consecutive  utility\n",
              "4       0.40                2   -967.5\n",
              "2       0.35                2  -1068.5\n",
              "5       0.40                3  -1220.0\n",
              "0       0.30                2  -1243.0\n",
              "3       0.35                3  -1243.0\n",
              "1       0.30                3  -1270.5"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7b9ffec9-e868-419c-9e73-d0fc0179ede6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>threshold</th>\n",
              "      <th>min_consecutive</th>\n",
              "      <th>utility</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.40</td>\n",
              "      <td>2</td>\n",
              "      <td>-967.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.35</td>\n",
              "      <td>2</td>\n",
              "      <td>-1068.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.40</td>\n",
              "      <td>3</td>\n",
              "      <td>-1220.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.30</td>\n",
              "      <td>2</td>\n",
              "      <td>-1243.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.35</td>\n",
              "      <td>3</td>\n",
              "      <td>-1243.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.30</td>\n",
              "      <td>3</td>\n",
              "      <td>-1270.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7b9ffec9-e868-419c-9e73-d0fc0179ede6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7b9ffec9-e868-419c-9e73-d0fc0179ede6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7b9ffec9-e868-419c-9e73-d0fc0179ede6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-6f876faa-7641-43fb-ab36-4812a054e7a3\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6f876faa-7641-43fb-ab36-4812a054e7a3')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-6f876faa-7641-43fb-ab36-4812a054e7a3 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_ae21f525-28e7-4eab-9bb2-92925fa6620a\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('results_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_ae21f525-28e7-4eab-9bb2-92925fa6620a button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('results_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "results_df",
              "summary": "{\n  \"name\": \"results_df\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"threshold\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04472135954999581,\n        \"min\": 0.3,\n        \"max\": 0.4,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.4,\n          0.35,\n          0.3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"min_consecutive\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 2,\n        \"max\": 3,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          3,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"utility\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 122.11255054252204,\n        \"min\": -1270.5,\n        \"max\": -967.5,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -1068.5,\n          -1270.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# FINAL TEST EVALUATION — v4 TIME-WEIGHTED MODEL (LOCKED)\n",
        "# ============================================================\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "MODEL_PATH = \"/content/drive/MyDrive/Thesis/PhysionetSepsis/models/best_model_v4_time_weighted.pt\"\n",
        "DATALOADER = test_loader\n",
        "\n",
        "LOCKED_THRESHOLD = 0.40        # ← replace after validation\n",
        "LOCKED_MIN_CONSECUTIVE = 2     # ← replace after validation\n",
        "MC_SAMPLES = 10\n",
        "\n",
        "print(\"FINAL TEST EVALUATION (v4)\")\n",
        "print(\"Model:\", MODEL_PATH)\n",
        "print(\"Threshold:\", LOCKED_THRESHOLD)\n",
        "print(\"Min consecutive:\", LOCKED_MIN_CONSECUTIVE)\n",
        "\n",
        "# -------------------------\n",
        "# Load model\n",
        "# -------------------------\n",
        "checkpoint = torch.load(MODEL_PATH, map_location=DEVICE)\n",
        "model = TemporalTransformer(NUM_FEATURES).to(DEVICE)\n",
        "model.load_state_dict(checkpoint[\"model_state\"])\n",
        "\n",
        "# -------------------------\n",
        "# Helpers\n",
        "# -------------------------\n",
        "def mc_mean_predict(model, X, M, DT, attn_mask, n_samples):\n",
        "    model.train()\n",
        "    probs = []\n",
        "    with torch.no_grad():\n",
        "        for _ in range(n_samples):\n",
        "            logits = model(X, M, DT, attn_mask)\n",
        "            probs.append(torch.sigmoid(logits))\n",
        "    return torch.stack(probs, dim=0).mean(dim=0)\n",
        "\n",
        "def temporal_smoothing(prob_seq, threshold, min_consecutive):\n",
        "    raw = (prob_seq >= threshold).astype(int)\n",
        "    smoothed = np.zeros_like(raw)\n",
        "    count = 0\n",
        "    for t in range(len(raw)):\n",
        "        if raw[t] == 1:\n",
        "            count += 1\n",
        "            if count >= min_consecutive:\n",
        "                smoothed[t] = 1\n",
        "        else:\n",
        "            count = 0\n",
        "    return smoothed\n",
        "\n",
        "# -------------------------\n",
        "# Evaluation\n",
        "# -------------------------\n",
        "total_utility = 0.0\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "for X, M, DT, Y, attn_mask in DATALOADER:\n",
        "    X, M, DT, Y, attn_mask = (\n",
        "        X.to(DEVICE),\n",
        "        M.to(DEVICE),\n",
        "        DT.to(DEVICE),\n",
        "        Y.to(DEVICE),\n",
        "        attn_mask.to(DEVICE),\n",
        "    )\n",
        "\n",
        "    mean_prob = mc_mean_predict(\n",
        "        model, X, M, DT, attn_mask, MC_SAMPLES\n",
        "    )\n",
        "\n",
        "    for i in range(X.size(0)):\n",
        "        length = int(attn_mask[i].sum())\n",
        "        p = mean_prob[i, :length].cpu().numpy()\n",
        "        y = Y[i, :length].cpu().numpy()\n",
        "\n",
        "        preds = temporal_smoothing(\n",
        "            p, LOCKED_THRESHOLD, LOCKED_MIN_CONSECUTIVE\n",
        "        )\n",
        "\n",
        "        total_utility += physionet_utility(y, preds)\n",
        "        correct += (preds == y).sum()\n",
        "        total += len(y)\n",
        "\n",
        "accuracy = correct / total\n",
        "\n",
        "print(\"--------------------------------------------------\")\n",
        "print(\"FINAL TEST RESULTS — v4 MODEL\")\n",
        "print(\"PhysioNet Utility Score :\", total_utility)\n",
        "print(\"Hourly Accuracy         :\", round(accuracy, 4))\n",
        "print(\"--------------------------------------------------\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UolZxAZKAqst",
        "outputId": "ee5e447e-8490-4170-afd9-2503fc15050f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FINAL TEST EVALUATION (v4)\n",
            "Model: /content/drive/MyDrive/Thesis/PhysionetSepsis/models/best_model_v4_time_weighted.pt\n",
            "Threshold: 0.4\n",
            "Min consecutive: 2\n",
            "--------------------------------------------------\n",
            "FINAL TEST RESULTS — v4 MODEL\n",
            "PhysioNet Utility Score : -1487.5\n",
            "Hourly Accuracy         : 0.9801\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TRIAL EVAL"
      ],
      "metadata": {
        "id": "hqxrMNw9EJ_5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# NEW DECISION POLICY: Early-Window Trigger + Smoothing\n",
        "# FINAL TEST EVALUATION (NO RETRAINING)\n",
        "# ============================================================\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# -------------------------\n",
        "# CONFIG (LOCKED)\n",
        "# -------------------------\n",
        "MODEL_PATH = \"/content/drive/MyDrive/Thesis/PhysionetSepsis/models/best_modelv3.pt\"\n",
        "DATALOADER = test_loader\n",
        "\n",
        "TAU_EARLY = 0.25          # early trigger threshold\n",
        "EARLY_WINDOW = 3          # hours\n",
        "TAU_MAIN = 0.35           # main threshold\n",
        "MIN_CONSECUTIVE = 2\n",
        "MC_SAMPLES = 10\n",
        "\n",
        "print(\"EARLY-WINDOW TEST EVALUATION\")\n",
        "print(\"Model:\", MODEL_PATH)\n",
        "print(f\"Early τ={TAU_EARLY}, window={EARLY_WINDOW}\")\n",
        "print(f\"Main τ={TAU_MAIN}, min_consec={MIN_CONSECUTIVE}\")\n",
        "\n",
        "# -------------------------\n",
        "# Load model\n",
        "# -------------------------\n",
        "checkpoint = torch.load(MODEL_PATH, map_location=DEVICE)\n",
        "model = TemporalTransformer(NUM_FEATURES).to(DEVICE)\n",
        "model.load_state_dict(checkpoint[\"model_state\"])\n",
        "\n",
        "# -------------------------\n",
        "# Helpers\n",
        "# -------------------------\n",
        "def mc_mean_predict(model, X, M, DT, attn_mask, n_samples):\n",
        "    model.train()\n",
        "    probs = []\n",
        "    with torch.no_grad():\n",
        "        for _ in range(n_samples):\n",
        "            logits = model(X, M, DT, attn_mask)\n",
        "            probs.append(torch.sigmoid(logits))\n",
        "    return torch.stack(probs, dim=0).mean(dim=0)\n",
        "\n",
        "def temporal_smoothing(prob_seq, threshold, min_consecutive):\n",
        "    raw = (prob_seq >= threshold).astype(int)\n",
        "    smoothed = np.zeros_like(raw)\n",
        "    count = 0\n",
        "    for t in range(len(raw)):\n",
        "        if raw[t] == 1:\n",
        "            count += 1\n",
        "            if count >= min_consecutive:\n",
        "                smoothed[t] = 1\n",
        "        else:\n",
        "            count = 0\n",
        "    return smoothed\n",
        "\n",
        "def early_window_trigger(prob_seq, tau_early, window):\n",
        "    preds = np.zeros_like(prob_seq, dtype=int)\n",
        "    for t in range(len(prob_seq)):\n",
        "        start = max(0, t - window + 1)\n",
        "        if np.max(prob_seq[start:t+1]) >= tau_early:\n",
        "            preds[t] = 1\n",
        "            preds[t:] = 1  # persistence\n",
        "            break\n",
        "    return preds\n",
        "\n",
        "# -------------------------\n",
        "# Evaluation\n",
        "# -------------------------\n",
        "total_utility = 0.0\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "for X, M, DT, Y, attn_mask in DATALOADER:\n",
        "    X, M, DT, Y, attn_mask = (\n",
        "        X.to(DEVICE),\n",
        "        M.to(DEVICE),\n",
        "        DT.to(DEVICE),\n",
        "        Y.to(DEVICE),\n",
        "        attn_mask.to(DEVICE),\n",
        "    )\n",
        "\n",
        "    mean_prob = mc_mean_predict(model, X, M, DT, attn_mask, MC_SAMPLES)\n",
        "\n",
        "    for i in range(X.size(0)):\n",
        "        length = int(attn_mask[i].sum())\n",
        "\n",
        "        p = mean_prob[i, :length].cpu().numpy()\n",
        "        y = Y[i, :length].cpu().numpy()\n",
        "\n",
        "        # Stage 1: early trigger\n",
        "        preds_early = early_window_trigger(\n",
        "            p, TAU_EARLY, EARLY_WINDOW\n",
        "        )\n",
        "\n",
        "        # Stage 2: fallback smoothing\n",
        "        if preds_early.sum() == 0:\n",
        "            preds = temporal_smoothing(\n",
        "                p, TAU_MAIN, MIN_CONSECUTIVE\n",
        "            )\n",
        "        else:\n",
        "            preds = preds_early\n",
        "\n",
        "        total_utility += physionet_utility(y, preds)\n",
        "        correct += (preds == y).sum()\n",
        "        total += len(y)\n",
        "\n",
        "accuracy = correct / total\n",
        "\n",
        "print(\"--------------------------------------------------\")\n",
        "print(\"EARLY-WINDOW TEST RESULTS\")\n",
        "print(\"PhysioNet Utility Score :\", total_utility)\n",
        "print(\"Hourly Accuracy         :\", round(accuracy, 4))\n",
        "print(\"--------------------------------------------------\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBmY8QebEL4g",
        "outputId": "c6f20c02-e861-4e29-92ac-6a81e3adf48f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EARLY-WINDOW TEST EVALUATION\n",
            "Model: /content/drive/MyDrive/Thesis/PhysionetSepsis/models/best_modelv3.pt\n",
            "Early τ=0.25, window=3\n",
            "Main τ=0.4, min_consec=2\n",
            "--------------------------------------------------\n",
            "EARLY-WINDOW TEST RESULTS\n",
            "PhysioNet Utility Score : -1584.5\n",
            "Hourly Accuracy         : 0.97\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **V5 TEST TRIAL**"
      ],
      "metadata": {
        "id": "5MvAJUZqHq9N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CELL V5-1 — Setup & Paths (NEW)"
      ],
      "metadata": {
        "id": "GACZQREWHzGm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# V5 EXPERIMENT — SETUP & PATHS (ALIGNED WITH EXISTING FOLDERS)\n",
        "# ============================================================\n",
        "\n",
        "import os\n",
        "import torch\n",
        "\n",
        "# Base directory (unchanged)\n",
        "BASE_DIR = \"/content/drive/MyDrive/Thesis/PhysionetSepsis\"\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Use EXISTING folders, namespace v5 inside them\n",
        "# ------------------------------------------------------------\n",
        "PROCESSED_DIR = os.path.join(BASE_DIR, \"processed\")\n",
        "MODELS_DIR = os.path.join(BASE_DIR, \"models\")\n",
        "LOGS_DIR = os.path.join(BASE_DIR, \"logs\")\n",
        "\n",
        "# Create if missing (safe)\n",
        "os.makedirs(PROCESSED_DIR, exist_ok=True)\n",
        "os.makedirs(MODELS_DIR, exist_ok=True)\n",
        "os.makedirs(LOGS_DIR, exist_ok=True)\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# V5-specific paths (NO overwrites)\n",
        "# ------------------------------------------------------------\n",
        "V5_PREPROCESSED_PATH = os.path.join(\n",
        "    PROCESSED_DIR, \"patients_v5_trends.pt\"\n",
        ")\n",
        "\n",
        "V5_MODEL_PATH = os.path.join(\n",
        "    MODELS_DIR, \"best_model_v5_trends.pt\"\n",
        ")\n",
        "\n",
        "V5_LOG_PATH = os.path.join(\n",
        "    LOGS_DIR, \"training_log_v5_trends.csv\"\n",
        ")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Print for verification\n",
        "# ------------------------------------------------------------\n",
        "print(\"V5 preprocessed data →\", V5_PREPROCESSED_PATH)\n",
        "print(\"V5 model checkpoint  →\", V5_MODEL_PATH)\n",
        "print(\"V5 training log      →\", V5_LOG_PATH)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAWHdUZhHuq2",
        "outputId": "6597d01d-0f83-458e-ee2e-11630794a964"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "V5 preprocessed data → /content/drive/MyDrive/Thesis/PhysionetSepsis/processed/patients_v5_trends.pt\n",
            "V5 model checkpoint  → /content/drive/MyDrive/Thesis/PhysionetSepsis/models/best_model_v5_trends.pt\n",
            "V5 training log      → /content/drive/MyDrive/Thesis/PhysionetSepsis/logs/training_log_v5_trends.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CELL V5-2 — Trend Feature Engineering Utilities (NEW)"
      ],
      "metadata": {
        "id": "BP41kBcwHwQO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# V5 — TREND FEATURE FUNCTIONS\n",
        "# ============================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def add_trend_features_v5(df, feature_cols):\n",
        "    \"\"\"\n",
        "    Adds explicit trend features:\n",
        "    - delta\n",
        "    - rolling mean (3h)\n",
        "    - rolling slope (3h)\n",
        "    No imputation is performed.\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    for col in feature_cols:\n",
        "        # Delta\n",
        "        df[f\"{col}_delta\"] = df[col].diff()\n",
        "\n",
        "        # Rolling mean (3 hours)\n",
        "        df[f\"{col}_mean3\"] = df[col].rolling(\n",
        "            window=3, min_periods=1\n",
        "        ).mean()\n",
        "\n",
        "        # Rolling slope (3 hours)\n",
        "        def slope(x):\n",
        "            if len(x) < 2:\n",
        "                return 0.0\n",
        "            t = np.arange(len(x))\n",
        "            return np.polyfit(t, x, 1)[0]\n",
        "\n",
        "        df[f\"{col}_slope3\"] = (\n",
        "            df[col]\n",
        "            .rolling(window=3, min_periods=2)\n",
        "            .apply(slope, raw=True)\n",
        "        )\n",
        "\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "ex-NDdj3HvYy"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CELL V5-3 — Preprocess Dataset with Trends (NEW, RUN ONCE)"
      ],
      "metadata": {
        "id": "Kru8LN23H_vv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# V5 DATA PREPROCESSING (OPTIMIZED, NO WARNINGS)\n",
        "# Trend features computed in batch\n",
        "# Saved to: processed/patients_v5_trends.pt\n",
        "# RUN ONCE ONLY\n",
        "# ============================================================\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# ---------------------\n",
        "# PATHS\n",
        "# ---------------------\n",
        "BASE_DIR = \"/content/drive/MyDrive/Thesis/PhysionetSepsis\"\n",
        "DATA_DIR = os.path.join(\n",
        "    BASE_DIR,\n",
        "    \"physionet.org/files/challenge-2019/1.0.0/training\"\n",
        ")\n",
        "\n",
        "SAVE_DIR = \"/content/drive/MyDrive/Thesis/PhysionetSepsis/processed\"\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "SAVE_PATH = os.path.join(SAVE_DIR, \"patients_v5_trends.pt\")\n",
        "\n",
        "print(\"Saving v5 processed data to:\")\n",
        "print(SAVE_PATH)\n",
        "\n",
        "# ---------------------\n",
        "# Raw PhysioNet features\n",
        "# ---------------------\n",
        "FEATURE_COLS_V5 = [\n",
        "    \"HR\",\"O2Sat\",\"Temp\",\"SBP\",\"MAP\",\"DBP\",\"Resp\",\"EtCO2\",\n",
        "    \"BaseExcess\",\"HCO3\",\"FiO2\",\"pH\",\"PaCO2\",\"SaO2\",\n",
        "    \"AST\",\"BUN\",\"Alkalinephos\",\"Calcium\",\"Chloride\",\n",
        "    \"Creatinine\",\"Bilirubin_direct\",\"Glucose\",\"Lactate\",\n",
        "    \"Magnesium\",\"Phosphate\",\"Potassium\",\"Bilirubin_total\",\n",
        "    \"TroponinI\",\"Hct\",\"Hgb\",\"PTT\",\"WBC\",\"Fibrinogen\",\n",
        "    \"Platelets\",\"Age\",\"Gender\",\"Unit1\",\"Unit2\",\"HospAdmTime\"\n",
        "]\n",
        "\n",
        "# ---------------------\n",
        "# Trend feature engineering (BATCHED)\n",
        "# ---------------------\n",
        "def add_trend_features_v5(df, feature_cols):\n",
        "    \"\"\"\n",
        "    Computes trend features in batch and concatenates once\n",
        "    to avoid DataFrame fragmentation.\n",
        "    \"\"\"\n",
        "    trend_features = {}\n",
        "\n",
        "    for col in feature_cols:\n",
        "        series = df[col]\n",
        "\n",
        "        # Delta\n",
        "        trend_features[f\"{col}_delta\"] = series.diff()\n",
        "\n",
        "        # Rolling mean (3 hours)\n",
        "        trend_features[f\"{col}_mean3\"] = series.rolling(\n",
        "            window=3, min_periods=1\n",
        "        ).mean()\n",
        "\n",
        "        # Rolling slope (3 hours)\n",
        "        def slope(x):\n",
        "            if len(x) < 2:\n",
        "                return 0.0\n",
        "            t = np.arange(len(x))\n",
        "            return np.polyfit(t, x, 1)[0]\n",
        "\n",
        "        trend_features[f\"{col}_slope3\"] = (\n",
        "            series\n",
        "            .rolling(window=3, min_periods=2)\n",
        "            .apply(slope, raw=True)\n",
        "        )\n",
        "\n",
        "    trend_df = pd.DataFrame(trend_features, index=df.index)\n",
        "\n",
        "    # Concatenate ONCE → no fragmentation\n",
        "    return pd.concat([df, trend_df], axis=1)\n",
        "\n",
        "# ---------------------\n",
        "# Build full feature list\n",
        "# ---------------------\n",
        "TREND_COLS_V5 = []\n",
        "for c in FEATURE_COLS_V5:\n",
        "    TREND_COLS_V5.extend([\n",
        "        f\"{c}_delta\",\n",
        "        f\"{c}_mean3\",\n",
        "        f\"{c}_slope3\"\n",
        "    ])\n",
        "\n",
        "ALL_FEATURE_COLS_V5 = FEATURE_COLS_V5 + TREND_COLS_V5\n",
        "NUM_FEATURES_V5 = len(ALL_FEATURE_COLS_V5)\n",
        "\n",
        "print(f\"Total v5 features: {NUM_FEATURES_V5}\")\n",
        "\n",
        "# ---------------------\n",
        "# Collect patient files\n",
        "# ---------------------\n",
        "psv_files = sorted(\n",
        "    glob.glob(os.path.join(DATA_DIR, \"training_setA\", \"*.psv\")) +\n",
        "    glob.glob(os.path.join(DATA_DIR, \"training_setB\", \"*.psv\"))\n",
        ")\n",
        "\n",
        "print(f\"Total patients: {len(psv_files)}\")\n",
        "\n",
        "# ---------------------\n",
        "# Process patients (REAL PROGRESS BAR)\n",
        "# ---------------------\n",
        "patients_v5 = []\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "with tqdm(\n",
        "    total=len(psv_files),\n",
        "    desc=\"V5 preprocessing\",\n",
        "    unit=\"patient\",\n",
        "    dynamic_ncols=True\n",
        ") as pbar:\n",
        "\n",
        "    for path in psv_files:\n",
        "        df = pd.read_csv(path, sep=\"|\")\n",
        "\n",
        "        # Add trend features (optimized)\n",
        "        df = add_trend_features_v5(df, FEATURE_COLS_V5)\n",
        "\n",
        "        # Labels\n",
        "        y = df[\"SepsisLabel\"].values.astype(np.float32)\n",
        "\n",
        "        # Feature matrix\n",
        "        X = df[ALL_FEATURE_COLS_V5].values.astype(np.float32)\n",
        "\n",
        "        # Missingness mask\n",
        "        M = ~np.isnan(X)\n",
        "\n",
        "        # Time since last measurement\n",
        "        DT = np.zeros_like(X)\n",
        "        for j in range(X.shape[1]):\n",
        "            last = -1\n",
        "            for t in range(len(X)):\n",
        "                if not np.isnan(X[t, j]):\n",
        "                    DT[t, j] = 0\n",
        "                    last = t\n",
        "                else:\n",
        "                    DT[t, j] = (t - last) if last >= 0 else 0\n",
        "\n",
        "        patients_v5.append({\n",
        "            \"X\": torch.tensor(np.nan_to_num(X, nan=0.0)),\n",
        "            \"M\": torch.tensor(M.astype(np.float32)),\n",
        "            \"DT\": torch.tensor(DT.astype(np.float32)),\n",
        "            \"Y\": torch.tensor(y),\n",
        "            \"length\": len(y)\n",
        "        })\n",
        "\n",
        "        pbar.update(1)\n",
        "\n",
        "elapsed = (time.time() - start_time) / 60\n",
        "\n",
        "# ---------------------\n",
        "# SAVE\n",
        "# ---------------------\n",
        "torch.save(\n",
        "    {\n",
        "        \"patients\": patients_v5,\n",
        "        \"feature_cols\": ALL_FEATURE_COLS_V5\n",
        "    },\n",
        "    SAVE_PATH\n",
        ")\n",
        "\n",
        "print(\"===================================================\")\n",
        "print(\"V5 preprocessing COMPLETE\")\n",
        "print(\"Saved to:\", SAVE_PATH)\n",
        "print(f\"Total time: {elapsed:.2f} minutes\")\n",
        "print(\"===================================================\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211,
          "referenced_widgets": [
            "52e61119c407483c87d93684fbd80e4d",
            "9478eb2d1a124a5fa8f5ede4924aeb04",
            "5443a5fd3f18467dacfe9c88751d08f2",
            "b853ebc9ec1a473fb8fe9461dd4ea051",
            "4d1888c97cb246a597f5b4a93c46abac",
            "4b3f714cb6064998af740b867c8a9bcf",
            "c7a2c8d47f0d460a872ae3a4cdab4602",
            "97673ff72f0942728421a639e4ad42da",
            "44121573c780484688b48bfbe743d119",
            "400bd34c202a4fd2899dd01c41ef8ec7",
            "60f654dc953b4483aa23ec2830f625b1"
          ]
        },
        "id": "b6jgiYzrIDr1",
        "outputId": "d185a6e6-cbad-44e6-f762-74eea960fbf2"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving v5 processed data to:\n",
            "/content/drive/MyDrive/Thesis/PhysionetSepsis/processed/patients_v5_trends.pt\n",
            "Total v5 features: 156\n",
            "Total patients: 40317\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "V5 preprocessing:   0%|          | 0/40317 [00:00<?, ?patient/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "52e61119c407483c87d93684fbd80e4d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===================================================\n",
            "V5 preprocessing COMPLETE\n",
            "Saved to: /content/drive/MyDrive/Thesis/PhysionetSepsis/processed/patients_v5_trends.pt\n",
            "Total time: 520.10 minutes\n",
            "===================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CELL V5-4 — Load Preprocessed v5 Data (FAST)\n",
        "\n",
        "Run this every time after runtime restart."
      ],
      "metadata": {
        "id": "Zp1VTt49IYRb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# V5 — LOAD PREPROCESSED DATA\n",
        "# ============================================================\n",
        "\n",
        "data = torch.load(\n",
        "    \"/content/drive/MyDrive/Thesis/PhysionetSepsis/processed/patients_v5_trends.pt\",\n",
        "    map_location=\"cpu\"\n",
        ")\n",
        "\n",
        "patients_v5 = data[\"patients\"]\n",
        "FEATURE_COLS_V5 = data[\"feature_cols\"]\n",
        "NUM_FEATURES_V5 = len(FEATURE_COLS_V5)\n",
        "\n",
        "print(\"Loaded v5 patients:\", len(patients_v5))\n",
        "print(\"NUM_FEATURES_V5:\", NUM_FEATURES_V5)"
      ],
      "metadata": {
        "id": "QtHHR3QrIaYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CELL V5-5 — Build Datasets & Loaders (NEW)\n",
        "\n",
        "Uses same split logic as v3 (patient-level, no leakage)."
      ],
      "metadata": {
        "id": "ma3MhTSYIfjy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# V5 — DATASET & DATALOADERS\n",
        "# ============================================================\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import random\n",
        "\n",
        "class ICUSequenceDataset(Dataset):\n",
        "    def __init__(self, patients):\n",
        "        self.patients = patients\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.patients)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        p = self.patients[idx]\n",
        "        return p[\"X\"], p[\"M\"], p[\"DT\"], p[\"Y\"], p[\"length\"]\n",
        "\n",
        "def collate_fn(batch):\n",
        "    Xs, Ms, DTs, Ys, lengths = zip(*batch)\n",
        "    max_len = max(lengths)\n",
        "\n",
        "    def pad(seq):\n",
        "        return torch.nn.functional.pad(\n",
        "            seq, (0, 0, 0, max_len - seq.shape[0])\n",
        "        )\n",
        "\n",
        "    X = torch.stack([pad(x) for x in Xs])\n",
        "    M = torch.stack([pad(m) for m in Ms])\n",
        "    DT = torch.stack([pad(dt) for dt in DTs])\n",
        "    Y = torch.stack([pad(y.unsqueeze(-1)).squeeze(-1) for y in Ys])\n",
        "\n",
        "    attn_mask = torch.zeros(len(lengths), max_len)\n",
        "    for i, l in enumerate(lengths):\n",
        "        attn_mask[i, :l] = 1\n",
        "\n",
        "    return X, M, DT, Y, attn_mask\n",
        "\n",
        "# ---------------------\n",
        "# Patient-level split (same ratios as v3)\n",
        "# ---------------------\n",
        "random.seed(42)\n",
        "random.shuffle(patients_v5)\n",
        "\n",
        "n = len(patients_v5)\n",
        "train_p = patients_v5[:int(0.7 * n)]\n",
        "val_p   = patients_v5[int(0.7 * n):int(0.85 * n)]\n",
        "test_p  = patients_v5[int(0.85 * n):]\n",
        "\n",
        "train_loader_v5 = DataLoader(\n",
        "    ICUSequenceDataset(train_p),\n",
        "    batch_size=8,\n",
        "    shuffle=True,\n",
        "    collate_fn=collate_fn\n",
        ")\n",
        "\n",
        "val_loader_v5 = DataLoader(\n",
        "    ICUSequenceDataset(val_p),\n",
        "    batch_size=8,\n",
        "    shuffle=False,\n",
        "    collate_fn=collate_fn\n",
        ")\n",
        "\n",
        "test_loader_v5 = DataLoader(\n",
        "    ICUSequenceDataset(test_p),\n",
        "    batch_size=8,\n",
        "    shuffle=False,\n",
        "    collate_fn=collate_fn\n",
        ")\n",
        "\n",
        "print(\"V5 loaders ready\")\n"
      ],
      "metadata": {
        "id": "xToA93agIhy1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CELL V5-6 — Train v5 Model (UNCHANGED LOGIC)\n",
        "\n",
        "You can now reuse your best training cell, with only:"
      ],
      "metadata": {
        "id": "pRjPn_cKIkKy"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VuFDm79uImc9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}